# scripts/update_dashboard.py
import os, json, time, argparse
from datetime import datetime, timedelta, timezone
import pandas as pd
import yfinance as yf
import requests

DATA_DIR = "data"
os.makedirs(DATA_DIR, exist_ok=True)

KST = timezone(timedelta(hours=9))

# --- ìœ í‹¸ ---
def save_json(path, obj):
    with open(path, "w", encoding="utf-8") as f:
        json.dump(obj, f, ensure_ascii=False, indent=2)

def load_json(path, default=None):
    if not os.path.exists(path): return default
    with open(path, "r", encoding="utf-8") as f:
        return json.load(f)

def pct(a, b):
    try:
        return round((a-b)/b*100, 2)
    except Exception:
        return None

# --- 1) ì§€ìˆ˜/í™˜ìœ¨ ìˆ˜ì§‘ ---
def fetch_market():
    # ì•¼í›„ íŒŒì´ë‚¸ìŠ¤ í‹°ì»¤
    tickers = {
        "KOSPI": "^KS11",
        "KOSDAQ": "^KQ11",
        "USDKRW": "KRW=X",
    }
    out = {"updated_at": datetime.now(KST).strftime("%Y-%m-%d %H:%M:%S")}
    for name, t in tickers.items():
        try:
            data = yf.Ticker(t).history(period="5d", interval="1d")
            if data.empty:
                out[name] = {"value": None, "change": None}
                continue
            last = float(data["Close"].iloc[-1])
            prev = float(data["Close"].iloc[-2]) if len(data) > 1 else last
            out[name] = {
                "value": round(last, 2),
                "change_pct": pct(last, prev),
                "dir": "â–²" if last >= prev else "â–¼",
            }
        except Exception:
            out[name] = {"value": None, "change": None}
    save_json(os.path.join(DATA_DIR, "market_today.json"), out)
    return out

# --- 2) ë‰´ìŠ¤ í—¤ë“œë¼ì¸(Optional: NEWSAPI) + í‚¤ì›Œë“œë§µ/í…Œë§ˆ Top5 ê°„ì´ ìƒì„± ---
KEYWORDS = [
    "AI","ë°˜ë„ì²´","ë¡œë´‡","ì´ì°¨ì „ì§€","ì›ì „","ë°”ì´ì˜¤","ì—ë„ˆì§€","ì¡°ì„ ","í•´ì–‘","ë””ì§€í„¸","ìˆ˜ì†Œ","ì „ê¸°ì°¨","ì¥ë¹„"
]

def fetch_headlines():
    key = os.environ.get("NEWSAPI_KEY")
    headlines = []
    if key:
        try:
            url = ("https://newsapi.org/v2/top-headlines?"
                   "country=kr&pageSize=40&apiKey="+key)
            r = requests.get(url, timeout=15)
            j = r.json()
            for it in j.get("articles", []):
                title = it.get("title") or ""
                url_ = it.get("url") or ""
                if title and url_:
                    headlines.append({"title": title, "url": url_})
        except Exception:
            pass
    # í‚¤ê°€ ì—†ê±°ë‚˜ ì‹¤íŒ¨í•˜ë©´ ê¸°ì¡´ ì•„ì¹´ì´ë¸Œ ìœ ì§€
    if not headlines:
        headlines = load_json(os.path.join(DATA_DIR, "recent_headlines.json"), [])
    # ìƒìœ„ 20ê°œë§Œ ìœ ì§€
    headlines = (headlines or [])[:20]
    save_json(os.path.join(DATA_DIR, "recent_headlines.json"), headlines)
    return headlines

def build_keyword_map(headlines):
    from collections import Counter
    cnt = Counter()
    for h in headlines:
        title = h["title"]
        for k in KEYWORDS:
            if k in title:
                cnt[k] += 1
    # ê¸°ë³¸ê°’
    if not cnt:
        for k in KEYWORDS: cnt[k]=0
    items = [{"keyword": k, "count": c} for k,c in cnt.most_common()]
    save_json(os.path.join(DATA_DIR, "keyword_map.json"), items)
    return items

def build_theme_top5(keyword_items):
    # count ê¸°ì¤€ ìƒìœ„ 5ê°œ
    sorted_kw = sorted(keyword_items, key=lambda x: x["count"], reverse=True)
    top5 = [{"theme": it["keyword"], "score": int(it["count"])} for it in sorted_kw[:5]]
    if not top5:
        top5 = [{"theme": "AI ë°˜ë„ì²´", "score": 10}]
    save_json(os.path.join(DATA_DIR, "theme_top5.json"), top5)
    return top5

# --- 3) í…”ë ˆê·¸ë¨ìš© ìš”ì•½ ---
def build_summary(market, top5, headlines):
    kospi = market.get("KOSPI", {})
    kosdaq = market.get("KOSDAQ", {})
    usdkrw = market.get("USDKRW", {})

    lines = []
    lines.append("*AI ë‰´ìŠ¤ ëŒ€ì‹œë³´ë“œ ì—…ë°ì´íŠ¸*")
    lines.append(f"ğŸ•’ {datetime.now(KST).strftime('%Y-%m-%d %H:%M')} (KST)")
    # ì§€ìˆ˜
    def fmt(name, d):
        v = d.get("value")
        cp = d.get("change_pct")
        arrow = d.get("dir","")
        if v is None or cp is None: return f"- {name}: ë°ì´í„° ì—†ìŒ"
        sign = "+" if cp>=0 else ""
        return f"- {name}: {v} ({arrow} {sign}{cp}%)"
    lines.append(fmt("KOSPI", kospi))
    lines.append(fmt("KOSDAQ", kosdaq))
    lines.append(fmt("USDKRW", usdkrw))
    # í…Œë§ˆ
    if top5:
        themes = ", ".join([t["theme"] for t in top5])
        lines.append(f"ğŸ”¥ Top5 í…Œë§ˆ: {themes}")
    # í—¤ë“œë¼ì¸
    if headlines:
        lines.append(f"ğŸ“° í—¤ë“œë¼ì¸ {len(headlines)}ê±´ ë°˜ì˜")
    return "\n".join(lines)

def main(summary_only=False):
    market = load_json(os.path.join(DATA_DIR, "market_today.json"))
    if not summary_only:
        market = fetch_market()
        headlines = fetch_headlines()
        kw = build_keyword_map(headlines)
        top5 = build_theme_top5(kw)
    else:
        headlines = load_json(os.path.join(DATA_DIR, "recent_headlines.json"), [])
        kw = load_json(os.path.join(DATA_DIR, "keyword_map.json"), [])
        top5 = load_json(os.path.join(DATA_DIR, "theme_top5.json"), [])

    msg = build_summary(market or {}, top5 or [], headlines or [])
    print(msg)

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--summary-only", action="store_true")
    args = parser.parse_args()
    main(summary_only=args.summary_only)
