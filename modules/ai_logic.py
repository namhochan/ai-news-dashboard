# -*- coding: utf-8 -*-
"""
AI ìš”ì•½ Â· ìë™ ë§¤í•‘ Â· ìœ ë§ ì¢…ëª© ì¶”ì²œ Â· (ì˜µì…˜) 3ì¼ ì˜ˆì¸¡
- summarize_news(news_list)
- show_ai_recommendations(theme_rows)
- predict_3day(tickers)  # ì„ íƒ ì‚¬ìš©
"""

import re
import difflib
from datetime import datetime
from collections import Counter
from typing import List, Dict, Tuple

import numpy as np
import pandas as pd
import streamlit as st
import yfinance as yf
from sklearn.linear_model import LogisticRegression
import FinanceDataReader as fdr

# ë‚´ë¶€ ëª¨ë“ˆ
from modules.news import fetch_category_news, THEME_KEYWORDS
from modules.market import fetch_quote

# -----------------------------
# 0) ê³µìš© ìœ í‹¸
# -----------------------------
def _fmt_number(v, d=2):
    try:
        if v is None or (isinstance(v, float) and (np.isnan(v) or np.isinf(v))): return "-"
        return f"{v:,.{d}f}"
    except Exception:
        return "-"

def _fmt_percent(v):
    try:
        if v is None or (isinstance(v, float) and (np.isnan(v) or np.isinf(v))): return "-"
        return f"{v:+.2f}%"
    except Exception:
        return "-"

def _valid_prices(last, prev):
    return last is not None and prev not in (None, 0) and np.isfinite(last) and np.isfinite(prev)

# -----------------------------
# 1) ë‰´ìŠ¤ ìš”ì•½/í‚¤ì›Œë“œ
# -----------------------------
def summarize_news(news_list: List[dict], topn_kw: int = 10, n_sent: int = 5):
    """ë‰´ìŠ¤ ì œëª©/ìš”ì•½ìœ¼ë¡œ í‚¤ì›Œë“œ TopN + ê°„ë‹¨ ìš”ì•½ë¬¸(ë”ë³´ê¸°í˜•) ì¶œë ¥"""
    titles = [(n.get("title") or "") for n in news_list]
    bodies = [f"{n.get('title','')} {n.get('desc','')}" for n in news_list]

    # í‚¤ì›Œë“œ
    words = []
    for t in titles:
        t = re.sub(r"[^ê°€-í£A-Za-z0-9\s]", " ", t)
        words += [w for w in t.split() if len(w) >= 2]
    top_kw = [w for w, _ in Counter(words).most_common(topn_kw)]

    st.markdown("### ğŸ“Œ í•µì‹¬ í‚¤ì›Œë“œ")
    st.write(", ".join(top_kw) if top_kw else "-")

    # ìš”ì•½
    full_text = " ".join(bodies)
    sents = [s.strip() for s in re.split(r"[.!?]\s+", full_text) if len(s.strip()) > 20]
    sents = sents[:n_sent]

    st.markdown("### ğŸ“° í•µì‹¬ ìš”ì•½ë¬¸")
    if sents:
        st.markdown(f"**ìš”ì•½:** {sents[0][:140]}...")
        with st.expander("ì „ì²´ ìš”ì•½ë¬¸ ë³´ê¸° ğŸ‘‡"):
            for s in sents:
                st.markdown(f"- {s}")
    else:
        st.info("ìš”ì•½ ë°ì´í„°ë¥¼ ìƒì„±í•˜ê¸°ì— í…ìŠ¤íŠ¸ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")

# -----------------------------
# 2) ìë™ ë§¤í•‘ (ë‰´ìŠ¤ â†” KRX ìƒì¥ì‚¬)
# -----------------------------
@st.cache_data(ttl=3600)
def _load_krx_listings():
    df = fdr.StockListing("KRX")
    df = df.rename(columns={"Symbol":"Code","Name":"Name"})
    for col in ["Name","Sector","Industry"]:
        if col not in df.columns: df[col] = ""
    df["name_l"]     = df["Name"].astype(str).str.lower()
    df["sector_l"]   = df["Sector"].astype(str).str.lower()
    df["industry_l"] = df["Industry"].astype(str).str.lower()
    return df[["Code","Name","Market","Sector","Industry","name_l","sector_l","industry_l"]]

def _kr_ticker(code: str) -> str | None:
    if not code or not re.fullmatch(r"\d{6}", str(code)): return None
    # ê°„ë‹¨ ì¶”ì •: 0/1/5/6/9 ì‹œì‘ = .KS, ê·¸ ì™¸ .KQ
    return f"{code}.KS" if str(code)[0] in "01569" else f"{code}.KQ"

def _extract_company_mentions(news_all: List[dict], listings: pd.DataFrame,
                              min_len: int = 2, sim_cutoff: float = 0.9) -> Dict[str, dict]:
    """
    ë‰´ìŠ¤ í…ìŠ¤íŠ¸ì—ì„œ ìƒì¥ì‚¬ 'íšŒì‚¬ëª…' ë“±ì¥/ìœ ì‚¬ì–´ë¡œ ì–¸ê¸‰ìˆ˜ ì§‘ê³„
    ë°˜í™˜: {íšŒì‚¬ëª…: {code, ticker, hits, sector, industry}}
    """
    names = listings["name_l"].tolist()
    idx_by_name = {n: i for i, n in enumerate(names)}
    counts = {}

    for n in news_all:
        text = (f"{n.get('title','')} {n.get('desc','')}".lower()).strip()
        if not text: continue

        # â‘  ë¶€ë¶„ì¼ì¹˜
        for i, row in listings.iterrows():
            nm = row["name_l"]
            if len(nm) < min_len: continue
            if nm and nm in text:
                code = row["Code"]; key = row["Name"]
                counts.setdefault(key, {"code":code, "ticker":_kr_ticker(code), "hits":0,
                                        "sector":row["Sector"], "industry":row["Industry"]})
                counts[key]["hits"] += 1

        # â‘¡ ìœ ì‚¬ë„ ë³´ì •
        tokens = [t for t in re.split(r"[^ê°€-í£A-Za-z0-9]+", text) if len(t) >= min_len]
        for tok in set(tokens):
            for cand in difflib.get_close_matches(tok, names, n=3, cutoff=sim_cutoff):
                row = listings.iloc[idx_by_name[cand]]
                code = row["Code"]; key = row["Name"]
                counts.setdefault(key, {"code":code, "ticker":_kr_ticker(code), "hits":0,
                                        "sector":row["Sector"], "industry":row["Industry"]})
                counts[key]["hits"] += 1
    return counts

def _auto_build_theme_stocks(theme_rows_df: pd.DataFrame, news_all: List[dict],
                             top_per_theme: int = 6,
                             extra_kws: Dict[str, List[str]] | None = None) -> Dict[str, List[Tuple[str,str]]]:
    """
    í…Œë§ˆë³„ ëŒ€í‘œ ì¢…ëª© ìë™ êµ¬ì„±:
    - ë‰´ìŠ¤â†’íšŒì‚¬ëª… ì–¸ê¸‰ ì§‘ê³„
    - íšŒì‚¬ëª…/ì„¹í„°/ì‚°ì—… í…ìŠ¤íŠ¸ì— 'í…Œë§ˆëª…' ë˜ëŠ” ì‚¬ìš©ì ì¶”ê°€ í‚¤ì›Œë“œ í¬í•¨ ì‹œ í›„ë³´
    - ì–¸ê¸‰ìˆ˜ ìƒìœ„ Nê°œ ë°˜í™˜
    """
    if theme_rows_df is None or theme_rows_df.empty:
        return {}

    listings = _load_krx_listings()
    mentions = _extract_company_mentions(news_all, listings)

    theme2stocks = {}
    for _, tr in theme_rows_df.iterrows():
        theme = str(tr["í…Œë§ˆ"])
        theme_kw = theme.lower()
        user_kws = [k.lower() for k in (extra_kws or {}).get(theme, [])]

        candidates = []
        for name, meta in mentions.items():
            blob = f"{name} {meta.get('sector','')} {meta.get('industry','')}".lower()
            if (theme_kw in blob) or any(k in blob for k in user_kws):
                if meta.get("ticker"):
                    candidates.append((name, meta["ticker"], meta["hits"]))
        # ì •ë ¬ + í‹°ì»¤ ì¤‘ë³µ ì œê±°
        candidates.sort(key=lambda x: x[2], reverse=True)
        seen = set(); uniq=[]
        for nm, tk, h in candidates:
            if tk in seen: continue
            seen.add(tk); uniq.append((nm, tk))
        theme2stocks[theme] = uniq[:top_per_theme]
    return theme2stocks

# -----------------------------
# 3) ìœ ë§ ì¢…ëª© ì¶”ì²œ
# -----------------------------
def _collect_all_news_for_3days() -> List[dict]:
    """ëª¨ë“  ì¹´í…Œê³ ë¦¬ì—ì„œ 3ì¼ì¹˜ í˜¸ì¶œ(ì¤‘ë³µ í¬í•¨)"""
    cats = ["ê²½ì œë‰´ìŠ¤","ì‚°ì—…ë‰´ìŠ¤","ì •ì±…ë‰´ìŠ¤"]
    out=[]
    for c in cats:
        out += fetch_category_news(c, days=3, max_items=120)
    return out

def _pick_promising(theme_rows_df: pd.DataFrame,
                    auto_theme_stocks: Dict[str, List[Tuple[str,str]]],
                    top_n: int = 5) -> pd.DataFrame:
    """ë‰´ìŠ¤ë¹ˆë„ + ë“±ë½ë¥  ê¸°ë°˜ TopN ì„ ë³„"""
    candidates=[]
    if theme_rows_df is None or theme_rows_df.empty:
        return pd.DataFrame()

    for _, tr in theme_rows_df.iterrows():
        theme = tr["í…Œë§ˆ"]
        count = int(tr["ë‰´ìŠ¤ê±´ìˆ˜"])
        for name, tk in auto_theme_stocks.get(theme, []):
            last, prev = fetch_quote(tk)
            if not _valid_prices(last, prev):
                continue
            delta = (last - prev) / prev * 100
            score = count * 0.3 + delta * 0.7
            candidates.append({"í…Œë§ˆ":theme, "ì¢…ëª©ëª…":name, "í‹°ì»¤":tk,
                               "ë“±ë½ë¥ (%)": round(delta,2), "ë‰´ìŠ¤ë¹ˆë„": count,
                               "AIì ìˆ˜": round(score,2)})
    df = pd.DataFrame(candidates)
    return df.sort_values("AIì ìˆ˜", ascending=False).head(top_n) if not df.empty else df

def show_ai_recommendations(theme_rows_df: pd.DataFrame):
    """
    - ìµœê·¼ 3ì¼ ëª¨ë“  ì¹´í…Œê³ ë¦¬ ë‰´ìŠ¤ ìˆ˜ì§‘
    - KRX ìë™ ë§¤í•‘ìœ¼ë¡œ í…Œë§ˆë³„ ëŒ€í‘œ ì¢…ëª© êµ¬ì„±
    - Top5 ìœ ë§ ì¢…ëª© ì¶œë ¥ + ê°„ë‹¨ ì½”ë©˜íŠ¸
    """
    st.markdown("## ğŸš€ ì˜¤ëŠ˜ì˜ AI ìœ ë§ ì¢…ëª© Top5")

    all_news = _collect_all_news_for_3days()
    auto_theme_stocks = _auto_build_theme_stocks(theme_rows_df, all_news, top_per_theme=6)

    if not auto_theme_stocks:
        st.info("ë‰´ìŠ¤-ì¢…ëª© ìë™ ë§¤í•‘ ê²°ê³¼ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤. í‚¤ì›Œë“œë¥¼ ë„“í˜€ë³´ì„¸ìš”.")
        return

    rec_df = _pick_promising(theme_rows_df, auto_theme_stocks, top_n=5)
    if rec_df.empty:
        st.info("ì¶”ì²œí•  ì¢…ëª©ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    st.dataframe(rec_df, use_container_width=True, hide_index=True)
    st.markdown("### ğŸ§¾ AI ì¢…í•© íŒë‹¨")
    for _, r in rec_df.iterrows():
        emoji = "ğŸ”º" if r["ë“±ë½ë¥ (%)"] > 0 else "ğŸ”»"
        st.markdown(
            f"- **{r['ì¢…ëª©ëª…']} ({r['í‹°ì»¤']})** â€” í…Œë§ˆ: *{r['í…Œë§ˆ']}*, "
            f"ë“±ë½ë¥  **{r['ë“±ë½ë¥ (%)']}%**, ë‰´ìŠ¤ë¹ˆë„ {r['ë‰´ìŠ¤ë¹ˆë„']}ê±´, AIì ìˆ˜ {r['AIì ìˆ˜']} {emoji}"
        )

# -----------------------------
# 4) (ì˜µì…˜) 3ì¼ ì˜ˆì¸¡ ëª¨ë“ˆ
# -----------------------------
@st.cache_data(ttl=900)
def _load_hist(ticker: str, period="2y"):
    df = yf.download(ticker, period=period, interval="1d", auto_adjust=True, progress=False)
    return df[~df.index.duplicated(keep='last')].dropna()

def _rsi(series: pd.Series, period: int = 14):
    delta = series.diff()
    up = np.where(delta > 0, delta, 0.0)
    down = np.where(delta < 0, -delta, 0.0)
    roll_up = pd.Series(up, index=series.index).rolling(period).mean()
    roll_down = pd.Series(down, index=series.index).rolling(period).mean().replace(0, np.nan)
    rs = roll_up / roll_down
    r = 100 - (100 / (1 + rs))
    return r.fillna(50)

def _macd(series: pd.Series, fast=12, slow=26, signal=9):
    ema_f = series.ewm(span=fast, adjust=False).mean()
    ema_s = series.ewm(span=slow, adjust=False).mean()
    line  = ema_f - ema_s
    sig   = line.ewm(span=signal, adjust=False).mean()
    hist  = line - sig
    return line, sig, hist

def _build_features(df: pd.DataFrame):
    price = df["Close"]
    feat = pd.DataFrame(index=df.index)
    feat["ret_1d"] = price.pct_change(1)
    feat["ret_5d"] = price.pct_change(5)
    feat["ret_10d"] = price.pct_change(10)
    feat["vol_5d"] = price.pct_change().rolling(5).std()
    feat["vol_20d"] = price.pct_change().rolling(20).std()
    feat["rsi_14"] = _rsi(price, 14)
    m, s, h = _macd(price)
    feat["macd"] = m; feat["macd_sig"] = s; feat["macd_hist"] = h
    ma5 = price.rolling(5).mean(); ma20 = price.rolling(20).mean()
    feat["ma5_gap"] = (price - ma5) / ma5
    feat["ma20_gap"] = (price - ma20) / ma20
    y = (price.shift(-1) > price).astype(int)
    return pd.concat([feat, y.rename("y")], axis=1).dropna()

def predict_3day(tickers: List[str]) -> pd.DataFrame:
    """
    ê°„ë‹¨ ë¡œì§€ìŠ¤í‹± íšŒê·€ë¡œ ë‚´ì¼/3ì¼ í‰ê·  ìƒìŠ¹í™•ë¥  ì¶”ì •
    - í˜¸ì¶œí•˜ëŠ” ìª½ì—ì„œ í‘œ/ì½”ë©˜íŠ¸ ë Œë”ë§ì„ ë‹´ë‹¹
    """
    rows=[]
    for tk in tickers:
        try:
            hist = _load_hist(tk)
            if hist is None or hist.empty:
                rows.append({"í‹°ì»¤": tk, "ë‚´ì¼ìƒìŠ¹í™•ë¥ ": "-", "3ì¼í‰ê· í™•ë¥ ": "-", "ì‹ í˜¸":"ë°ì´í„°ë¶€ì¡±"})
                continue
            feats = _build_features(hist)
            if len(feats) < 120:
                rows.append({"í‹°ì»¤": tk, "ë‚´ì¼ìƒìŠ¹í™•ë¥ ": "-", "3ì¼í‰ê· í™•ë¥ ": "-", "ì‹ í˜¸":"ë°ì´í„°ë¶€ì¡±"})
                continue
            data = feats.tail(300)
            X = data.drop(columns=["y"]).values
            y = data["y"].values
            n = len(data); split = max(60, n-3)
            X_train, y_train = X[:split], y[:split]
            X_pred = X[split:]
            model = LogisticRegression(max_iter=300)
            model.fit(X_train, y_train)
            prob = model.predict_proba(X_pred)[:,1]
            p1 = float(prob[0]) if len(prob)>0 else None
            p3 = float(prob.mean()) if len(prob)>0 else None
            if p1 is None:
                rows.append({"í‹°ì»¤": tk, "ë‚´ì¼ìƒìŠ¹í™•ë¥ ": "-", "3ì¼í‰ê· í™•ë¥ ": "-", "ì‹ í˜¸":"ë°ì´í„°ë¶€ì¡±"})
            else:
                sig = "ë§¤ìˆ˜ê´€ì‹¬" if p1>=0.55 else ("ê´€ë§" if p1>=0.45 else "ì£¼ì˜")
                rows.append({"í‹°ì»¤": tk, "ë‚´ì¼ìƒìŠ¹í™•ë¥ ": round(p1*100,1), "3ì¼í‰ê· í™•ë¥ ": round(p3*100,1), "ì‹ í˜¸": sig})
        except Exception:
            rows.append({"í‹°ì»¤": tk, "ë‚´ì¼ìƒìŠ¹í™•ë¥ ": "-", "3ì¼í‰ê· í™•ë¥ ": "-", "ì‹ í˜¸":"ì˜¤ë¥˜"})
    return pd.DataFrame(rows)
