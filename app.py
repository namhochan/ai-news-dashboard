import streamlit as st
import plotly.express as px
import json, os, time, csv, io
from datetime import datetime
import pytz
from pathlib import Path

st.set_page_config(page_title="AI ë‰´ìŠ¤ë¦¬í¬íŠ¸ V26.0 â€“ Web Dashboard", page_icon="ğŸ“Š", layout="wide")
st.markdown("""
<style>
.block-container { padding-top: 1.1rem; padding-bottom: 1.1rem; }
h1, h2, h3 { line-height: 1.25; }
</style>
""", unsafe_allow_html=True)

KST = pytz.timezone("Asia/Seoul")

# ---------- utils ----------
def load_json(path):
    p = Path(path)
    if not p.exists(): return None
    try: return json.loads(p.read_text(encoding="utf-8"))
    except Exception: return None

def fmt_mtime(path):
    try:
        ts = os.path.getmtime(path)
        return time.strftime("%Y-%m-%d %H:%M", time.localtime(ts))
    except Exception:
        return "-"

def to_float(x):
    try: return float(x)
    except: return None

def normalize_metric(blob):
    """ìƒˆí¬ë§·({'value','pct'})/êµ¬í¬ë§·(ìˆ«ì/ë¬¸ìì—´) ëª¨ë‘ {'value', 'pct'}ë¡œ ë§ì¶¤"""
    if isinstance(blob, dict):
        v = to_float(blob.get("value"))
        pct = blob.get("pct")
        try: pct = float(pct) if pct is not None else None
        except: pct = None
        return {"value": v, "pct": pct}
    else:
        return {"value": to_float(blob), "pct": None}

def fmt_val(x): return "-" if x is None else f"{x:,.2f}"

def reltime(txt):
    try:
        if "T" in txt:
            dt = datetime.strptime(txt[:19], "%Y-%m-%dT%H:%M:%S")
        else:
            dt = datetime.strptime(txt[:25], "%a, %d %b %Y %H:%M:%S")
        dt = KST.localize(dt)
        mins = int((datetime.now(KST)-dt).total_seconds()//60)
        if mins < 1: return "ë°©ê¸ˆ ì „"
        if mins < 60: return f"{mins}ë¶„ ì „"
        return f"{mins//60}ì‹œê°„ ì „"
    except: return ""

def dedup_by_title(items, limit=50):
    seen, out = set(), []
    for it in items or []:
        key = (it.get("title") or "").strip().lower()
        if key and key not in seen:
            seen.add(key); out.append(it)
        if len(out) >= limit: break
    return out

def sanitize_kwmap(kmap):
    clean = []
    for k, v in (kmap or {}).items():
        try: n = int(float(v))
        except: continue
        if n > 0: clean.append((k, n))
    clean.sort(key=lambda x: x[1], reverse=True)
    return clean

# ---------- load data ----------
def read_all():
    return (
        load_json("data/market_today.json") or {},
        load_json("data/theme_top5.json") or [],
        load_json("data/keyword_map.json") or {},
        load_json("data/headlines.json") or [],
    )

if "last_reload" not in st.session_state:
    st.session_state.last_reload = time.time()

with st.sidebar:
    st.caption("âš™ï¸ ë°ì´í„°")
    if st.button("ğŸ”„ íŒŒì¼ ë‹¤ì‹œ ì½ê¸°"): st.session_state.last_reload = time.time()

market, themes, keyword_map, headlines = read_all()

# ---------- header ----------
st.title("ğŸ“Š AI ë‰´ìŠ¤ë¦¬í¬íŠ¸ V26.0 â€“ Web Dashboard Edition")
st.caption("ìë™ ìƒì„±í˜• ë‰´ìŠ¤Â·í…Œë§ˆÂ·ìˆ˜ê¸‰ ë¶„ì„ ë¦¬í¬íŠ¸ (ì‹¤ì‹œê°„ ë°ì´í„° ê¸°ë°˜)")
st.caption(f"â± ì‹œì¥ì§€í‘œ ê°±ì‹ : {fmt_mtime('data/market_today.json')} Â· í—¤ë“œë¼ì¸ ê°±ì‹ : {fmt_mtime('data/headlines.json')} (KST)")

# ---------- sidebar filter/export ----------
with st.sidebar:
    st.markdown("---")
    st.caption("ğŸ” í—¤ë“œë¼ì¸ í•„í„°")
    query = st.text_input("í‚¤ì›Œë“œ í¬í•¨", "")
    sources = sorted({(h.get("source") or "").strip() for h in (headlines or []) if h.get("source")})
    sel_sources = st.multiselect("ì¶œì²˜ ì„ íƒ(ì˜µì…˜)", sources, default=[])
    st.markdown("---")
    st.caption("â¬‡ï¸ ë‚´ë³´ë‚´ê¸°")
    if headlines:
        buf = io.StringIO()
        writer = csv.DictWriter(buf, fieldnames=["title","url","source","published"])
        writer.writeheader()
        for h in headlines:
            writer.writerow({
                "title": h.get("title",""), "url": h.get("url",""),
                "source": h.get("source",""), "published": h.get("published","")
            })
        st.download_button("í—¤ë“œë¼ì¸ CSV", buf.getvalue().encode("utf-8-sig"),
                           file_name="headlines.csv", mime="text/csv")
        st.download_button("í—¤ë“œë¼ì¸ JSON",
                           json.dumps(headlines, ensure_ascii=False, indent=2).encode("utf-8"),
                           file_name="headlines.json", mime="application/json")

# ---------- market ----------
st.header("ğŸ“‰ ì˜¤ëŠ˜ì˜ ì‹œì¥ ìš”ì•½")
def draw_metric(col, label, raw, inverse=False):
    m = normalize_metric(raw)
    v = fmt_val(m["value"])
    if m["pct"] is None: col.metric(label, v)
    else:
        sign = "+" if m["pct"] >= 0 else ""
        col.metric(label, v, delta=f"{sign}{m['pct']:.2f}%",
                   delta_color=("inverse" if inverse else "normal"))

c1, c2, c3 = st.columns(3)
draw_metric(c1, "KOSPI",  market.get("KOSPI"),  inverse=False)
draw_metric(c2, "KOSDAQ", market.get("KOSDAQ"), inverse=False)
draw_metric(c3, "í™˜ìœ¨(USD/KRW)", market.get("USD_KRW"), inverse=True)
if market: st.caption("ë©”ëª¨: " + market.get("comment",""))

# ---------- themes ----------
st.header("ğŸ”¥ TOP 5 í…Œë§ˆ")
if themes:
    for t in themes:
        st.subheader("ğŸ“ˆ " + t.get("name","í…Œë§ˆ"))
        st.caption(t.get("summary",""))
        st.progress(int(t.get("strength",60)))
        stocks = t.get("stocks", [])
        if stocks: st.caption("ëŒ€í‘œ ì¢…ëª©: " + ", ".join(stocks))
        st.link_button("ê´€ë ¨ ë‰´ìŠ¤ ë³´ê¸°", t.get("news_link","https://news.google.com/?hl=ko&gl=KR&ceid=KR:ko"))
        st.divider()
else:
    st.info("í…Œë§ˆ ë°ì´í„°ê°€ ì•„ì§ ì—†ìŠµë‹ˆë‹¤. ìë™ ì—…ë°ì´íŠ¸ í›„ í‘œì‹œë©ë‹ˆë‹¤.")

# ---------- headlines ----------
st.header("ğŸ“° ìµœê·¼ í—¤ë“œë¼ì¸ Top 10")
filtered = dedup_by_title(headlines, limit=80)
if query: filtered = [x for x in filtered if query.lower() in (x.get("title","").lower())]
if sel_sources: filtered = [x for x in filtered if (x.get("source") or "").strip() in sel_sources]

if filtered:
    for item in filtered[:10]:
        title = item.get("title","(ì œëª©ì—†ìŒ)")
        url   = item.get("url","#")
        src   = item.get("source","")
        when  = reltime(item.get("published",""))
        meta  = " Â· ".join([x for x in [src, when] if x])
        st.markdown(f"- [{title}]({url})  \n  <span style='color:#9aa0a6;font-size:90%'>{meta}</span>", unsafe_allow_html=True)
    with st.expander("ë” ë³´ê¸° (11~40)"):
        for item in filtered[10:40]:
            title = item.get("title","(ì œëª©ì—†ìŒ)")
            url   = item.get("url","#")
            src   = item.get("source","")
            when  = reltime(item.get("published",""))
            meta  = " Â· ".join([x for x in [src, when] if x])
            st.markdown(f"- [{title}]({url})  \n  <span style='color:#9aa0a6;font-size:90%'>{meta}</span>", unsafe_allow_html=True)
else:
    st.caption("í—¤ë“œë¼ì¸ ë°ì´í„°ê°€ ì•„ì§ ì—†ìŠµë‹ˆë‹¤. ìë™ ì—…ë°ì´íŠ¸ ì´í›„ í‘œì‹œë©ë‹ˆë‹¤.")

# ---------- keyword map ----------
st.header("ğŸŒ ì›”ê°„ í‚¤ì›Œë“œë§µ")
items = sanitize_kwmap(keyword_map)[:15]
if items:
    kw, cnt = zip(*items)
    fig = px.bar(x=list(kw), y=list(cnt),
                 labels={"x":"í‚¤ì›Œë“œ","y":"ë“±ì¥íšŸìˆ˜"}, text=list(cnt))
    fig.update_traces(textposition="outside")
    fig.update_layout(xaxis_tickangle=-30, height=420, margin=dict(l=10,r=10,t=10,b=10))
    st.plotly_chart(fig, use_container_width=True, config={"displayModeBar": False})
else:
    st.caption("í‚¤ì›Œë“œ ë°ì´í„°ê°€ ë¹„ì–´ìˆê±°ë‚˜ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ë‹¤ìŒ ìë™ ì—…ë°ì´íŠ¸ í›„ ë‹¤ì‹œ í™•ì¸í•˜ì„¸ìš”.")            
