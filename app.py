# -*- coding: utf-8 -*-
import math, re, difflib
from datetime import datetime, timedelta, date
from zoneinfo import ZoneInfo
from urllib.parse import quote_plus
from collections import Counter

import numpy as np
import pandas as pd
import streamlit as st
import yfinance as yf
import feedparser
from bs4 import BeautifulSoup
from sklearn.linear_model import LogisticRegression
import FinanceDataReader as fdr

KST = ZoneInfo("Asia/Seoul")
st.set_page_config(page_title="AI ë‰´ìŠ¤ë¦¬í¬íŠ¸ â€“ ìë™ í…Œë§ˆÂ·ì‹œì„¸ ì˜ˆì¸¡", layout="wide")

# -------------------------
# ê³µí†µ ìœ í‹¸
# -------------------------
def now_kst_str(): return datetime.now(KST).strftime("%Y-%m-%d %H:%M:%S (KST)")
def fmt_number(v, d=2):
    try:
        if v is None or (isinstance(v, float) and (math.isnan(v) or math.isinf(v))): return "-"
        return f"{v:,.{d}f}"
    except Exception: return "-"
def fmt_percent(v):
    try:
        if v is None or (isinstance(v, float) and (math.isnan(v) or math.isinf(v))): return "-"
        return f"{v:+.2f}%"
    except Exception: return "-"

def valid_prices(last, prev):
    return last is not None and prev not in (None, 0) and all(map(np.isfinite, [last, prev]))

# -------------------------
# ì‹œì„¸
# -------------------------
@st.cache_data(ttl=900)
def fetch_quote(ticker: str):
    try:
        t = yf.Ticker(ticker)
        last = getattr(t.fast_info, "last_price", None)
        prev = getattr(t.fast_info, "previous_close", None)
        if valid_prices(last, prev): return float(last), float(prev)
    except Exception:
        pass
    try:
        df = yf.download(ticker, period="7d", interval="1d", progress=False, auto_adjust=False)
        c = df.get("Close")
        if c is None or c.dropna().empty: return None, None
        c = c.dropna()
        last = float(c.iloc[-1]); prev = float(c.iloc[-2]) if len(c) >= 2 else None
        return last, prev
    except Exception:
        return None, None

# -------------------------
# ë‰´ìŠ¤ (Google RSS)
# -------------------------
def clean_html(raw): return BeautifulSoup(raw or "", "html.parser").get_text(" ", strip=True)

@st.cache_data(ttl=900)
def fetch_google_news_by_keyword(keyword, days=3, limit=50):
    q = quote_plus(keyword)
    url = f"https://news.google.com/rss/search?q={q}&hl=ko&gl=KR&ceid=KR%3Ako"
    feed = feedparser.parse(url, request_headers={"User-Agent": "Mozilla/5.0"})
    now = datetime.now(KST)
    out = []
    for e in getattr(feed, "entries", []):
        t = None
        if getattr(e, "published_parsed", None):
            t = datetime(*e.published_parsed[:6], tzinfo=KST)
        elif getattr(e, "updated_parsed", None):
            t = datetime(*e.updated_parsed[:6], tzinfo=KST)
        if t and (now - t) > timedelta(days=days): 
            continue
        title, link = e.get("title", ""), e.get("link", "")
        if link.startswith("./"): link = "https://news.google.com/" + link[2:]
        out.append({"title": title.strip(), "link": link.strip(),
                    "time": t.strftime("%Y-%m-%d %H:%M") if t else "-",
                    "desc": clean_html(e.get("summary",""))})
    # ìµœì‹ ìˆœ
    def key(x):
        try: return datetime.strptime(x["time"], "%Y-%m-%d %H:%M")
        except: return datetime.min
    out.sort(key=key, reverse=True)
    return out[:limit]

CATEGORIES = {
    "ê²½ì œë‰´ìŠ¤": ["ê²½ì œ","ê¸ˆë¦¬","ë¬¼ê°€","í™˜ìœ¨","ì„±ì¥ë¥ ","ë¬´ì—­"],
    "ì£¼ì‹ë‰´ìŠ¤": ["ì½”ìŠ¤í”¼","ì½”ìŠ¤ë‹¥","ì¦ì‹œ","ì£¼ê°€","ì™¸êµ­ì¸ ë§¤ìˆ˜","ê¸°ê´€ ë§¤ë„"],
    "ì‚°ì—…ë‰´ìŠ¤": ["ë°˜ë„ì²´","AI","ë°°í„°ë¦¬","ìë™ì°¨","ë¡œë´‡","ì „ë ¥","ì „ê¸°ìš”ê¸ˆ","ì—ë„ˆì§€","ë°ì´í„°ì„¼í„°"],
    "ì •ì±…ë‰´ìŠ¤": ["ì •ì±…","ì •ë¶€","ì˜ˆì‚°","ê·œì œ","ì„¸ê¸ˆ","ì‚°ì—…ë¶€","ê¸ˆìœµìœ„ì›íšŒ"],
}

@st.cache_data(ttl=900)
def fetch_category_news(cat, days=3, max_items=120):
    seen, out = set(), []
    for kw in CATEGORIES.get(cat, []):
        for it in fetch_google_news_by_keyword(kw, days, 50):
            k = (it["title"], it["link"])
            if k in seen: continue
            seen.add(k); out.append(it)
    return out[:max_items]

# -------------------------
# KRX ìë™ ë§¤í•‘ ìœ í‹¸
# -------------------------
@st.cache_data(ttl=3600)
def load_krx_listings():
    df = fdr.StockListing("KRX")
    df = df.rename(columns={"Symbol":"Code","Name":"Name"})
    for col in ["Name","Sector","Industry"]:
        if col not in df.columns: df[col] = ""
    df["name_l"]    = df["Name"].astype(str).str.lower()
    df["sector_l"]  = df["Sector"].astype(str).str.lower()
    df["industry_l"]= df["Industry"].astype(str).str.lower()
    return df[["Code","Name","Market","Sector","Industry","name_l","sector_l","industry_l"]]

def _kr_ticker(code: str) -> str|None:
    if not code or not re.fullmatch(r"\d{6}", str(code)): return None
    return f"{code}.KS" if str(code)[0] in "01569" else f"{code}.KQ"

def extract_company_mentions(news_list, listings, min_len=2, sim_cutoff=0.9):
    idx_by_name = {n: i for i, n in enumerate(listings["name_l"].tolist())}
    names = list(idx_by_name.keys())
    counts = {}
    for n in news_list:
        text = (n.get("title","") + " " + n.get("desc","")).lower()
        if not text: continue

        # 1) ë¶€ë¶„ì¼ì¹˜
        for i, row in listings.iterrows():
            nm = row["name_l"]
            if len(nm) < min_len: continue
            if nm and nm in text:
                code = row["Code"]; key = row["Name"]
                counts.setdefault(key, {"code":code,"ticker":_kr_ticker(code), "hits":0,
                                        "sector":row["Sector"], "industry":row["Industry"]})
                counts[key]["hits"] += 1

        # 2) ìœ ì‚¬ë„ ë³´ì •
        tokens = [t for t in re.split(r"[^ê°€-í£A-Za-z0-9]+", text) if len(t) >= min_len]
        for tok in set(tokens):
            for cand in difflib.get_close_matches(tok, names, n=3, cutoff=sim_cutoff):
                i = idx_by_name[cand]
                row = listings.iloc[i]
                code = row["Code"]; key = row["Name"]
                counts.setdefault(key, {"code":code,"ticker":_kr_ticker(code), "hits":0,
                                        "sector":row["Sector"], "industry":row["Industry"]})
                counts[key]["hits"] += 1
    return counts  # {íšŒì‚¬ëª…: {code,ticker,hits,sector,industry}}

def auto_build_theme_stocks(theme_rows, news_all, top_per_theme=6, extra_kws:dict|None=None):
    """
    ë‰´ìŠ¤ í…ìŠ¤íŠ¸ â†” KRX ìƒì¥ì‚¬ ìë™ ë§¤í•‘, í…Œë§ˆ í‚¤ì›Œë“œë¥¼ ì—…ì¢…/ì‚°ì—…/íšŒì‚¬ëª…ì— ëŒ€ì¡°
    extra_kws: í…Œë§ˆ ê´€ë¦¬ìì—ì„œ ë“¤ì–´ì˜¨ ì‚¬ìš©ì í‚¤ì›Œë“œ(dict)
    """
    listings = load_krx_listings()
    mentions = extract_company_mentions(news_all, listings)
    # í…Œë§ˆë³„ í›„ë³´ ì„ ë³„
    theme2stocks = {}
    for tr in theme_rows:
        theme = tr["theme"]
        theme_kw = theme.lower()
        user_kws = [k.lower() for k in (extra_kws or {}).get(theme, [])]
        candidates = []
        for name, meta in mentions.items():
            textblob = f"{name} {meta.get('sector','')} {meta.get('industry','')}".lower()
            ok = (theme_kw in textblob) or any(k in textblob for k in user_kws)
            if ok and meta.get("ticker"):
                candidates.append((name, meta["ticker"], meta["hits"]))
        # ì–¸ê¸‰ìˆ˜ ë‚´ë¦¼ì°¨ìˆœ
        candidates.sort(key=lambda x: x[2], reverse=True)
        # ì¤‘ë³µ ì œê±°(í‹°ì»¤ ê¸°ì¤€)
        seen=set(); uniq=[]
        for nm, tk, h in candidates:
            if tk in seen: continue
            seen.add(tk); uniq.append((nm, tk, h))
        theme2stocks[theme] = [(nm, tk) for nm, tk, _ in uniq[:top_per_theme]]
    return theme2stocks

# -------------------------
# ìŠ¤íƒ€ì¼ (í‹°ì»¤ë°” + ì¹´ë“œ + í€µë©”ë‰´ ì´ˆì†Œí˜•)
# -------------------------
CSS = """
<style>
.ticker-wrap{overflow:hidden;width:100%;border:1px solid #263042;border-radius:10px;background:#0f1420;}
.ticker-track{display:flex;gap:12px;align-items:center;width:max-content;animation:ticker-scroll var(--speed,32s) linear infinite;}
@keyframes ticker-scroll{0%{transform:translateX(0);}100%{transform:translateX(-50%);}}
.badge{display:inline-flex;align-items:center;gap:6px;background:#0f1420;border:1px solid #2b3a55;
  color:#c7d2fe;padding:4px 8px;border-radius:8px;font-weight:700;white-space:nowrap;font-size:0.9rem}
.badge .name{color:#9fb3c8;font-weight:600;}
.badge .up{color:#e66;} .badge .down{color:#6aa2ff;} .sep{color:#44526b;padding:0 4px;}
.small{font-size:.85rem;color:#9aa0a6}
.card-grid{display:grid;grid-template-columns:repeat(4,1fr);gap:10px;margin:8px 0 18px}
.stock-card{border:1px solid #263042;border-radius:10px;padding:10px;background:#0f1420}
.stock-card .nm{font-weight:700}
.stock-card .px{margin-top:3px}
.stock-card .px.up{color:#e66}
.stock-card .px.down{color:#6aa2ff}
.stock-card .px.flat{color:#a3aab8}
@media (max-width: 1000px){.card-grid{grid-template-columns:repeat(2,1fr)}}
.compact-item{margin-bottom:.45rem}
.compact-item .when{color:#9aa0a6;font-size:.85rem}
#MainMenu, footer {visibility:hidden;}
.quickbar{position:fixed;left:4px;top:24%;background:#0f1420;border:1px solid #2b3a55;border-radius:10px;
  padding:6px 6px; font-size:.72rem; z-index:9999; opacity:.80}
.quickbar a{display:block;color:#d0daee;text-decoration:none;margin:3px 0; padding:3px 6px; border-radius:6px;}
.quickbar a:hover{background:#14233a}
.section-h{scroll-margin-top:70px;}
</style>
"""
st.markdown(CSS, unsafe_allow_html=True)

# -------------------------
# í—¤ë”/í‹°ì»¤ë°”/ìƒˆë¡œê³ ì¹¨
# -------------------------
st.markdown(f"#### ğŸ§  AI ë‰´ìŠ¤ë¦¬í¬íŠ¸ â€” ì—…ë°ì´íŠ¸: {now_kst_str()}")
if st.button("ğŸ”„ ìƒˆë¡œê³ ì¹¨"): st.cache_data.clear(); st.rerun()

@st.cache_data(ttl=900)
def build_ticker_items():
    rows=[("KOSPI","^KS11",2),("KOSDAQ","^KQ11",2),
          ("DOW","^DJI",2),("NASDAQ","^IXIC",2),
          ("USD/KRW","KRW=X",2),("WTI","CL=F",2),
          ("Gold","GC=F",2),("Copper","HG=F",3)]
    items=[]
    for name,ticker,dp in rows:
        last, prev = fetch_quote(ticker)
        d=p=None
        if valid_prices(last, prev):
            d=last-prev; p=(d/prev)*100
        items.append({"name":name,"last":fmt_number(last,dp),
                      "pct":fmt_percent(p) if p is not None else "--",
                      "is_up":(d or 0)>0,"is_down":(d or 0)<0})
    return items

def render_ticker_line(items, speed_sec=32):
    chips=[]
    for it in items:
        arrow="â–²" if it["is_up"] else ("â–¼" if it["is_down"] else "â€¢")
        cls="up" if it["is_up"] else ("down" if it["is_down"] else "")
        chips.append(f"<span class='badge'><span class='name'>{it['name']}</span>{it['last']} <span class='{cls}'>{arrow} {it['pct']}</span></span>")
    line='<span class="sep">|</span>'.join(chips)
    st.markdown(f"<div class='ticker-wrap'><div class='ticker-track' style='--speed:{speed_sec}s'>{line}<span class='sep'>|</span>{line}</div></div>", unsafe_allow_html=True)

render_ticker_line(build_ticker_items())
st.caption("â€» ìƒìŠ¹=ë¹¨ê°•, í•˜ë½=íŒŒë‘ Â· ë°ì´í„°: Yahoo Finance (ì§€ì—° ê°€ëŠ¥)")

# -------------------------
# ì´ˆì†Œí˜• í€µë©”ë‰´
# -------------------------
st.markdown("""
<div class='quickbar'>
<a href='#sec-news'>ğŸ“° ìµœì‹ </a>
<a href='#sec-theme'>ğŸ”¥ í…Œë§ˆ</a>
<a href='#sec-summary'>ğŸ“‘ ìš”ì•½</a>
<a href='#sec-prob'>ğŸ“ˆ í™•ë¥ </a>
<a href='#sec-top'>ğŸš€ Top5</a>
<a href='#sec-3d'>ğŸ”® 3ì¼</a>
<a href='#sec-admin'>ğŸ›  ê´€ë¦¬</a>
</div>
""", unsafe_allow_html=True)

# -------------------------
# ìµœì‹  ë‰´ìŠ¤ (ì œëª© + ì‹œê°„, ì»´íŒ©íŠ¸)
# -------------------------
st.markdown('<div id="sec-news" class="section-h"></div>', unsafe_allow_html=True)
st.divider(); st.markdown("## ğŸ“° ìµœì‹  ë‰´ìŠ¤ ìš”ì•½")
c1,c2 = st.columns([2,1])
with c1: cat = st.selectbox("ğŸ“‚ ì¹´í…Œê³ ë¦¬", list(CATEGORIES))
with c2: page = st.number_input("í˜ì´ì§€", 1, 99, 1, 1)

news_all = fetch_category_news(cat, days=3, max_items=120)
pg = 10
chunk = news_all[(page-1)*pg : page*pg]
if not chunk:
    st.info("í‘œì‹œí•  ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
else:
    for it in chunk:
        st.markdown(
            f"<div class='compact-item'>"
            f"<a href='{it['link']}' target='_blank'><b>{it['title']}</b></a><br>"
            f"<span class='when'>{it['time']}</span>"
            f"</div>", unsafe_allow_html=True
        )
st.caption(f"ìµœê·¼ 3ì¼ Â· {cat} Â· {len(news_all)}ê±´ ì¤‘ {(page-1)*pg+1}-{min(page*pg,len(news_all))} í‘œì‹œ")

# -------------------------
# í…Œë§ˆ í‚¤ì›Œë“œ(ê¸°ë³¸) + ê´€ë¦¬ì ì„¸ì…˜
# -------------------------
DEFAULT_THEME_KWS = {
    "AI":["ai","ì¸ê³µì§€ëŠ¥","ì±—ë´‡","ì—”ë¹„ë””ì•„","ì˜¤í”ˆai","ìƒì„±í˜•","gpu"],
    "ë°˜ë„ì²´":["ë°˜ë„ì²´","hbm","ì¹©","ë¨","íŒŒìš´ë“œë¦¬","ì†Œë¶€ì¥"],
    "ë¡œë´‡":["ë¡œë´‡","ììœ¨ì£¼í–‰","í˜‘ë™ë¡œë´‡","amr","ë¡œë³´í‹±ìŠ¤"],
    "ì´ì°¨ì „ì§€":["ë°°í„°ë¦¬","ì „ê³ ì²´","ì–‘ê·¹ì¬","ìŒê·¹ì¬","lfp"],
    "ì—ë„ˆì§€":["ì—ë„ˆì§€","ì •ìœ ","ì „ë ¥","íƒœì–‘ê´‘","í’ë ¥","ê°€ìŠ¤","ë°œì „","ì „ê¸°ìš”ê¸ˆ"],
    "ì¡°ì„ ":["ì¡°ì„ ","ì„ ë°•","lngì„ ","í•´ìš´","ìˆ˜ì£¼"],
    "LNG":["lng","ì•¡í™”ì²œì—°ê°€ìŠ¤","ê°€ìŠ¤ê³µì‚¬","í„°ë¯¸ë„"],
    "ì›ì „":["ì›ì „","smr","ì›ìë ¥","ìš°ë¼ëŠ„","ì •ë¹„"],
    "ë°”ì´ì˜¤":["ë°”ì´ì˜¤","ì œì•½","ì‹ ì•½","ì„ìƒ","ì‹œë°€ëŸ¬"],
}
if "CUSTOM_THEME_KWS" not in st.session_state:
    st.session_state.CUSTOM_THEME_KWS = {}     # {í…Œë§ˆ: [ì‚¬ìš©ì í‚¤ì›Œë“œ]}
if "PINNED_STOCKS" not in st.session_state:
    st.session_state.PINNED_STOCKS = {}        # {í…Œë§ˆ: [(ì´ë¦„,í‹°ì»¤), ...]}

def merged_theme_kws():
    merged = {k: list(set(v)) for k,v in DEFAULT_THEME_KWS.items()}
    for t, kws in st.session_state.CUSTOM_THEME_KWS.items():
        merged.setdefault(t, [])
        merged[t] = list(set(merged[t] + kws))
    return merged

# -------------------------
# ë‰´ìŠ¤ ê¸°ë°˜ í…Œë§ˆ ê°ì§€
# -------------------------
st.markdown('<div id="sec-theme" class="section-h"></div>', unsafe_allow_html=True)
st.divider(); st.markdown("## ğŸ”¥ ë‰´ìŠ¤ ê¸°ë°˜ í…Œë§ˆ ìš”ì•½")

def detect_themes(news_list, theme_kws:dict):
    counts = {t: 0 for t in theme_kws}
    sample = {t: "" for t in theme_kws}
    for n in news_list:
        text = (n.get("title","") + " " + n.get("desc","")).lower()
        for t, kws in theme_kws.items():
            if any(k in text for k in kws):
                counts[t] += 1
                if not sample[t]: sample[t] = n.get("link","")
    rows = []
    for t,c in counts.items():
        if c>0:
            rows.append({"theme":t,"count":int(c),"sample":sample[t]})
    rows.sort(key=lambda x: x["count"], reverse=True)
    return rows

# ì „ì²´ ë‰´ìŠ¤ 3ì¼ì¹˜
news_cache = {k: fetch_category_news(k, 3, 120) for k in CATEGORIES}
all_news = []
for v in news_cache.values(): all_news.extend(v)

THEME_KEYWORDS = merged_theme_kws()
theme_rows = detect_themes(all_news, THEME_KEYWORDS)

if not theme_rows:
    st.info("ìµœê·¼ 3ì¼ ê¸°ì¤€ í…Œë§ˆ ì‹ í˜¸ê°€ ì•½í•©ë‹ˆë‹¤.")
else:
    st.markdown("**TOP í…Œë§ˆ:** " + " ".join([f"ğŸŸ¢ {r['theme']}({r['count']})" for r in theme_rows[:5]]))
    df_theme = pd.DataFrame(theme_rows)
    # ë§í¬ ì»¬ëŸ¼
    try:
        df_theme["ìƒ˜í”Œ ë‰´ìŠ¤"] = df_theme["sample"]
        st.dataframe(df_theme[["theme","count","ìƒ˜í”Œ ë‰´ìŠ¤"]].rename(columns={"theme":"í…Œë§ˆ","count":"ë‰´ìŠ¤ê±´ìˆ˜"}),
                     use_container_width=True, hide_index=True,
                     column_config={"ìƒ˜í”Œ ë‰´ìŠ¤": st.column_config.LinkColumn("ìƒ˜í”Œ ë‰´ìŠ¤", display_text="ì—´ê¸°")})
    except Exception:
        st.dataframe(df_theme.rename(columns={"theme":"í…Œë§ˆ","count":"ë‰´ìŠ¤ê±´ìˆ˜"}), use_container_width=True, hide_index=True)

# -------------------------
# ìë™ ë§¤í•‘ìœ¼ë¡œ ëŒ€í‘œ ì¢…ëª© êµ¬ì„±
# -------------------------
extra_kws = st.session_state.CUSTOM_THEME_KWS
auto_theme_stocks = auto_build_theme_stocks(theme_rows, all_news, top_per_theme=6, extra_kws=extra_kws)

st.markdown("### ğŸ§© ëŒ€í‘œ ì¢…ëª© ì‹œì„¸ (ìë™ ë§¤í•‘ Â· ìƒìŠ¹=ë¹¨ê°•/í•˜ë½=íŒŒë‘)")
def rep_price(tk):
    l,p = fetch_quote(tk)
    if not valid_prices(l,p): return None, None, "flat"
    d = (l-p)/p*100
    tone = "up" if d>0 else ("down" if d<0 else "flat")
    return fmt_number(l,0), fmt_percent(d), tone

for tr in theme_rows[:5]:
    theme = tr["theme"]
    # ì‚¬ìš©ì PINNEDê°€ ìˆìœ¼ë©´ ìš°ì„ 
    stocks = st.session_state.PINNED_STOCKS.get(theme) or auto_theme_stocks.get(theme, [])
    st.markdown(f"**{theme}**  <span class='small'>ë‰´ìŠ¤ {tr['count']}ê±´</span>", unsafe_allow_html=True)
    if not stocks:
        st.caption("Â· ê¸°ì‚¬ì—” í…Œë§ˆê°€ ë§ì§€ë§Œ ì¢…ëª©ëª…ì´ ì¶©ë¶„íˆ ì–¸ê¸‰ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        st.divider(); continue
    cards=[]
    for nm, tk in stocks[:6]:
        px, chg, tone = rep_price(tk)
        arrow = "â–²" if tone=="up" else ("â–¼" if tone=="down" else "â– ")
        html = (f"<div class='stock-card'><div class='nm'>{nm}</div>"
                f"<div class='ticker'>{tk}</div>"
                f"<div class='px {tone}'>{px if px else '-'} {arrow if px else ''} {chg if px else ''}</div></div>")
        cards.append(html)
    st.markdown(f"<div class='card-grid'>{''.join(cards)}</div>", unsafe_allow_html=True)
    st.divider()

# -------------------------
# AI ë‰´ìŠ¤ ìš”ì•½ì—”ì§„
# -------------------------
st.markdown('<div id="sec-summary" class="section-h"></div>', unsafe_allow_html=True)
st.divider(); st.markdown("## ğŸ“‘ AI ë‰´ìŠ¤ ìš”ì•½ì—”ì§„")

titles = [n["title"] for n in all_news]
words=[]
for t in titles:
    t = re.sub(r"[^ê°€-í£A-Za-z0-9\s]"," ",t)
    words += [w for w in t.split() if len(w)>=2]
top_kw = [w for w,_ in Counter(words).most_common(10)]
st.write("ğŸ“Œ í‚¤ì›Œë“œ:", ", ".join(top_kw) if top_kw else "-")

full_text = " ".join([n.get("title","")+" "+n.get("desc","") for n in all_news])
sentences = [s for s in re.split(r'[.!?]\s+', full_text) if len(s.strip())>20][:5]
if sentences:
    st.markdown(f"**ìš”ì•½:** {sentences[0][:140]}...")
    with st.expander("ì „ì²´ ìš”ì•½ë¬¸ ë³´ê¸° ğŸ‘‡"):
        for s in sentences: st.markdown(f"- {s.strip()}")
else:
    st.info("ìš”ì•½ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

# -------------------------
# í…Œë§ˆë³„ ìƒìŠ¹ í™•ë¥  ë¦¬í¬íŠ¸
# -------------------------
st.markdown('<div id="sec-prob" class="section-h"></div>', unsafe_allow_html=True)
st.divider(); st.markdown("## ğŸ“ˆ AI ìƒìŠ¹ í™•ë¥  ì˜ˆì¸¡ ë¦¬í¬íŠ¸")

def calc_theme_strength(count, avg_delta):
    freq = min(count/20, 1.0)
    prc  = min(max((avg_delta+5)/10, 0), 1.0)
    return round((freq*0.6 + prc*0.4)*5, 1)

def calc_risk_level(avg_delta):
    if avg_delta >= 3: return 1
    if avg_delta >= 1: return 2
    if avg_delta >= -1: return 3
    if avg_delta >= -3: return 4
    return 5

report=[]
for tr in theme_rows[:5]:
    theme = tr["theme"]
    deltas=[]
    for nm, tk in (auto_theme_stocks.get(theme, [])[:6]):
        l,p = fetch_quote(tk)
        if valid_prices(l,p): deltas.append((l-p)/p*100)
    avg = float(np.mean(deltas)) if deltas else 0.0
    report.append({"í…Œë§ˆ":theme,"ë‰´ìŠ¤ê±´ìˆ˜":tr["count"],"í‰ê· ë“±ë½(%)":round(avg,2),
                   "í…Œë§ˆê°•ë„(1~5)":calc_theme_strength(tr["count"],avg),
                   "ë¦¬ìŠ¤í¬ë ˆë²¨(1~5)":calc_risk_level(avg)})
st.dataframe(pd.DataFrame(report), use_container_width=True, hide_index=True)

# -------------------------
# ìœ ë§ ì¢…ëª© Top5
# -------------------------
st.markdown('<div id="sec-top" class="section-h"></div>', unsafe_allow_html=True)
st.divider(); st.markdown("## ğŸš€ ì˜¤ëŠ˜ì˜ AI ìœ ë§ ì¢…ëª© Top5")

def pick_promising_stocks(theme_rows, top_n=5):
    cands=[]
    for tr in theme_rows[:8]:
        theme = tr["theme"]
        for name, tk in auto_theme_stocks.get(theme, []):
            l,p = fetch_quote(tk)
            if not valid_prices(l,p): continue
            delta = (l-p)/p*100
            score = tr["count"]*0.3 + delta*0.7
            cands.append({"í…Œë§ˆ":theme,"ì¢…ëª©ëª…":name,"í‹°ì»¤":tk,
                          "ë“±ë½ë¥ (%)":round(delta,2),"ë‰´ìŠ¤ë¹ˆë„":tr["count"],"AIì ìˆ˜":round(score,2)})
    df = pd.DataFrame(cands)
    return df.sort_values("AIì ìˆ˜", ascending=False).head(top_n) if not df.empty else df

recommend_df = pick_promising_stocks(theme_rows, 5)
if recommend_df.empty:
    st.info("ì¶”ì²œí•  ì¢…ëª©ì´ ì—†ìŠµë‹ˆë‹¤.")
else:
    st.dataframe(recommend_df, use_container_width=True, hide_index=True)
    st.markdown("### ğŸ§¾ AI ì¢…í•© íŒë‹¨")
    for _, r in recommend_df.iterrows():
        emoji = "ğŸ”º" if r["ë“±ë½ë¥ (%)"]>0 else "ğŸ”»"
        st.markdown(f"- **{r['ì¢…ëª©ëª…']} ({r['í‹°ì»¤']})** â€” í…Œë§ˆ: *{r['í…Œë§ˆ']}*, "
                    f"ë“±ë½ë¥  **{r['ë“±ë½ë¥ (%)']}%**, ë‰´ìŠ¤ë¹ˆë„ {r['ë‰´ìŠ¤ë¹ˆë„']}ê±´, AIì ìˆ˜ {r['AIì ìˆ˜']}")

# -------------------------
# 3ì¼ ì˜ˆì¸¡ ëª¨ë“ˆ
# -------------------------
st.markdown('<div id="sec-3d" class="section-h"></div>', unsafe_allow_html=True)
st.divider(); st.markdown("## ğŸ”® AI 3ì¼ ì˜ˆì¸¡: ë‚´ì¼ ì˜¤ë¥¼ í™•ë¥ ")

@st.cache_data(ttl=900)
def load_hist(ticker: str, period="2y"):
    df = yf.download(ticker, period=period, interval="1d", auto_adjust=True, progress=False)
    return df[~df.index.duplicated(keep='last')].dropna()

def rsi(series: pd.Series, period: int = 14):
    delta = series.diff()
    up = np.where(delta > 0, delta, 0.0)
    down = np.where(delta < 0, -delta, 0.0)
    roll_up = pd.Series(up, index=series.index).rolling(period).mean()
    roll_down = pd.Series(down, index=series.index).rolling(period).mean().replace(0, np.nan)
    rs = roll_up / roll_down
    r = 100 - (100 / (1 + rs))
    return r.fillna(50)

def macd(series: pd.Series, fast=12, slow=26, signal=9):
    ema_f = series.ewm(span=fast, adjust=False).mean()
    ema_s = series.ewm(span=slow, adjust=False).mean()
    line = ema_f - ema_s
    sig  = line.ewm(span=signal, adjust=False).mean()
    hist = line - sig
    return line, sig, hist

def build_features(df: pd.DataFrame):
    price = df["Close"]
    feat = pd.DataFrame(index=df.index)
    feat["ret_1d"] = price.pct_change(1)
    feat["ret_5d"] = price.pct_change(5)
    feat["ret_10d"] = price.pct_change(10)
    feat["vol_5d"] = price.pct_change().rolling(5).std()
    feat["vol_20d"] = price.pct_change().rolling(20).std()
    feat["rsi_14"] = rsi(price, 14)
    m, s, h = macd(price)
    feat["macd"] = m; feat["macd_sig"] = s; feat["macd_hist"] = h
    ma5 = price.rolling(5).mean(); ma20 = price.rolling(20).mean()
    feat["ma5_gap"] = (price-ma5)/ma5
    feat["ma20_gap"] = (price-ma20)/ma20
    y = (price.shift(-1) > price).astype(int)
    return pd.concat([feat, y.rename("y")], axis=1).dropna()

def fit_predict_prob(df_feat: pd.DataFrame):
    if len(df_feat) < 120: return None, None
    data = df_feat.tail(300)
    X = data.drop(columns=["y"]).values
    y = data["y"].values
    n = len(data); split = max(60, n-3)
    X_train, y_train = X[:split], y[:split]
    X_pred = X[split:]
    model = LogisticRegression(max_iter=300)
    model.fit(X_train, y_train)
    prob = model.predict_proba(X_pred)[:,1]
    p1 = float(prob[0]) if len(prob)>0 else None
    p3 = float(prob.mean()) if len(prob)>0 else None
    return p1, p3

rows=[]
if recommend_df.empty:
    st.info("ë¨¼ì € Top5ê°€ ìƒì„±ë˜ì–´ì•¼ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆì–´ìš”.")
else:
    with st.spinner("ì˜ˆì¸¡ ê³„ì‚° ì¤‘..."):
        for _, r in recommend_df.iterrows():
            name, tk = r["ì¢…ëª©ëª…"], r["í‹°ì»¤"]
            try:
                feats = build_features(load_hist(tk))
                p1, p3 = fit_predict_prob(feats)
                if p1 is None:
                    rows.append({"ì¢…ëª©ëª…":name,"í‹°ì»¤":tk,"ë‚´ì¼ìƒìŠ¹í™•ë¥ ":"-","3ì¼í‰ê· í™•ë¥ ":"-","ì‹ í˜¸":"ë°ì´í„°ë¶€ì¡±"})
                else:
                    sig = "ë§¤ìˆ˜ê´€ì‹¬" if p1>=0.55 else ("ê´€ë§" if p1>=0.45 else "ì£¼ì˜")
                    rows.append({"ì¢…ëª©ëª…":name,"í‹°ì»¤":tk,"ë‚´ì¼ìƒìŠ¹í™•ë¥ ":round(p1*100,1),
                                 "3ì¼í‰ê· í™•ë¥ ":round(p3*100,1),"ì‹ í˜¸":sig})
            except Exception:
                rows.append({"ì¢…ëª©ëª…":name,"í‹°ì»¤":tk,"ë‚´ì¼ìƒìŠ¹í™•ë¥ ":"-","3ì¼í‰ê· í™•ë¥ ":"-","ì‹ í˜¸":"ì˜¤ë¥˜"})

pred_df = pd.DataFrame(rows)
if not pred_df.empty:
    def _prob_color(v):
        try: v=float(v)
        except: return ""
        if v>=60: return "background-color: rgba(217,48,37,.18); color:#ffd2cf; font-weight:700;"
        if v>=50: return "background-color: rgba(255,193,7,.12);"
        return "background-color: rgba(26,115,232,.14); color:#d7e6ff;"
    st.dataframe(pred_df.style.map(_prob_color, subset=["ë‚´ì¼ìƒìŠ¹í™•ë¥ ","3ì¼í‰ê· í™•ë¥ "]),
                 use_container_width=True, hide_index=True)
    st.markdown("### ğŸ§  AI ì¸ì‚¬ì´íŠ¸")
    for _, row in pred_df.iterrows():
        if row["ë‚´ì¼ìƒìŠ¹í™•ë¥ "] == "-":
            st.markdown(f"- **{row['ì¢…ëª©ëª…']} ({row['í‹°ì»¤']})** â€” ë°ì´í„° ë¶€ì¡±/ì˜¤ë¥˜")
        else:
            arrow = "ğŸ”º" if row["ë‚´ì¼ìƒìŠ¹í™•ë¥ "]>=50 else "ğŸ”»"
            st.markdown(f"- **{row['ì¢…ëª©ëª…']} ({row['í‹°ì»¤']})** â€” ë‚´ì¼ ìƒìŠ¹ í™•ë¥  **{row['ë‚´ì¼ìƒìŠ¹í™•ë¥ ']}%** "
                        f"(3ì¼ í‰ê·  {row['3ì¼í‰ê· í™•ë¥ ']}%), ì‹ í˜¸ **{row['ì‹ í˜¸']}** {arrow}")

# -------------------------
# í…Œë§ˆ ê´€ë¦¬ì (ì‘ê²Œ)
# -------------------------
st.markdown('<div id="sec-admin" class="section-h"></div>', unsafe_allow_html=True)
st.divider(); st.markdown("## ğŸ›  í…Œë§ˆ ê´€ë¦¬ì (í‚¤ì›Œë“œ/í•€ ê³ ì • ì €ì¥)")

with st.form("theme_admin", clear_on_submit=False):
    st.markdown("### í…Œë§ˆ í‚¤ì›Œë“œ ì¶”ê°€")
    t1 = st.text_input("í…Œë§ˆëª… (ì˜ˆ: ì „ë ¥)")
    kw = st.text_input("í‚¤ì›Œë“œ(ì½¤ë§ˆêµ¬ë¶„, ì˜ˆ: ì „ë ¥, í•œì „, ì „ê¸°ìš”ê¸ˆ)")
    st.markdown("---")
    st.markdown("### ëŒ€í‘œ ì¢…ëª© í•€ ê³ ì • (í…Œë§ˆì— ìš°ì„  ì ìš©)")
    t2 = st.text_input("í…Œë§ˆëª…(í•€ ê³ ì •ìš©)")
    st.markdown("ì´ë¦„|í‹°ì»¤ í•œ ì¤„ì”© (ì˜ˆ: í•œêµ­ì „ë ¥|015760.KS)")
    pin_txt = st.text_area("í•€ ëª©ë¡", height=90, placeholder="í•œêµ­ì „ë ¥|015760.KS\ní•œì „KPS|051600.KS")
    ok = st.form_submit_button("ğŸ’¾ ì €ì¥")

    if ok:
        if t1.strip():
            kws = [x.strip() for x in kw.split(",") if x.strip()]
            st.session_state.CUSTOM_THEME_KWS.setdefault(t1, [])
            st.session_state.CUSTOM_THEME_KWS[t1] = list(set(st.session_state.CUSTOM_THEME_KWS[t1] + kws))
            st.success(f"í…Œë§ˆ í‚¤ì›Œë“œ ì €ì¥: {t1} â†’ {', '.join(kws) if kws else '-'}")
        if t2.strip():
            pairs=[]
            for ln in [l.strip() for l in pin_txt.splitlines() if "|" in l]:
                nm, tk = ln.split("|",1)
                nm, tk = nm.strip(), tk.strip()
                if nm and tk: pairs.append((nm, tk))
            st.session_state.PINNED_STOCKS[t2] = pairs
            st.success(f"í•€ ê³ ì • ì €ì¥: {t2} â†’ {len(pairs)}ê°œ")

if st.session_state.CUSTOM_THEME_KWS:
    st.caption("**ì¶”ê°€ëœ í‚¤ì›Œë“œ**")
    for k,v in st.session_state.CUSTOM_THEME_KWS.items():
        st.write(f"- {k}: {', '.join(v)}")
if st.session_state.PINNED_STOCKS:
    st.caption("**í•€ ê³ ì • ì¢…ëª©**")
    for k,v in st.session_state.PINNED_STOCKS.items():
        st.write(f"- {k}: {', '.join([f'{n}({t})' for n,t in v])}")
