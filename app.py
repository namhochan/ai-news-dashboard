# app.py â€” ì•ˆì •íŒ v2 (ì§€ìˆ˜ ë°±ì—…ì‹¬ë³¼ + í™•ì¥ í…Œë§ˆì‚¬ì „ + ë¶ˆìš©ì–´ í•„í„°)
import re, json
from datetime import datetime, timezone, timedelta
from typing import Dict, List

import streamlit as st
import pandas as pd
import yfinance as yf
import feedparser
from urllib.parse import quote

# -------------------- ê¸°ë³¸ ì„¤ì • --------------------
KST = timezone(timedelta(hours=9))
st.set_page_config(page_title="AI ë‰´ìŠ¤ë¦¬í¬íŠ¸ ì¢…í•© ëŒ€ì‹œë³´ë“œ", layout="wide")
st.markdown("# ğŸ§  AI ë‰´ìŠ¤ë¦¬í¬íŠ¸ ì¢…í•© ëŒ€ì‹œë³´ë“œ (ìë™ ì—…ë°ì´íŠ¸)")
st.caption("ì—…ë°ì´íŠ¸ ì‹œê°„: " + datetime.now(KST).strftime("%Y-%m-%d %H:%M:%S (KST)"))

# -------------------- ìœ í‹¸ --------------------
def normalize_item(x) -> Dict[str, str]:
    """ë‰´ìŠ¤ í•­ëª©ì„ {'title','link'}ë¡œ ê°•ì œ"""
    try:
        if isinstance(x, dict) or "FeedParserDict" in x.__class__.__name__:
            t = str(x.get("title", "")).strip()
            l = str(x.get("link", "")).strip()
            return {"title": t, "link": l}
    except Exception:
        pass
    s = str(x).strip()
    return {"title": s, "link": ""}

def clean_title(t: str) -> str:
    """ì œëª©ì—ì„œ ë¶ˆìš© ìˆ˜ì‹/ê´„í˜¸/ë‚ ì§œ/ë§¤ì²´ ê¼¬ë¦¬í‘œ ì œê±°"""
    t = re.sub(r"\[[^\]]+\]", " ", t)        # [ë‹¨ë…], [ì†ë³´] ë“±
    t = re.sub(r"\([^\)]+\)", " ", t)        # (ì˜ìƒ), (ì¢…í•©) ë“±
    t = re.sub(r"\d{1,2}ì›”|\d{1,2}ì¼|\d{4}ë…„|\d{4}-\d{1,2}-\d{1,2}", " ", t)
    t = re.sub(r"[-â€“â€”]\s*[ê°€-í£A-Za-z0-9_.]+(ì¼ë³´|ì‹ ë¬¸|ê²½ì œ|ë‰´ìŠ¤|ë„·|TV|Biz|biz|net|com)$", " ", t)
    t = re.sub(r"\s{2,}", " ", t).strip()
    return t

# -------------------- ì§€ìˆ˜/í™˜ìœ¨/ì›ìì¬ --------------------
# ì‹¬ë³¼ í›„ë³´ë¥¼ ì—¬ëŸ¬ ê°œ ë‘ê³  ìˆœì°¨ ì‹œë„ (ì§€ì—­/ì„¸ì…˜ì— ë”°ë¼ ì¼ë¶€ ë¹ˆê°’ ë°©ì§€)
SYMS = {
    "KOSPI":  ["^KS11", "^KS200"],              # ì½”ìŠ¤í”¼ / ì½”ìŠ¤í”¼200 ë°±ì—…
    "KOSDAQ": ["^KQ11", "^KOSDAQ", "KOSDAQ.KQ"],# ì½”ìŠ¤ë‹¥ í›„ë³´
    "USDKRW": ["KRW=X"],
    "WTI":    ["CL=F"],
    "Gold":   ["GC=F"],
    "Copper": ["HG=F"],
}

def _last_two_close_v2(ticker: str):
    try:
        tk = yf.Ticker(ticker)
        df = tk.history(period="2mo", interval="1d", auto_adjust=True)
        closes = df["Close"].dropna().tail(2).tolist()
        if len(closes) == 2:
            return float(closes[-1]), float(closes[-2])
        elif len(closes) == 1:
            return float(closes[0]), None
    except Exception:
        pass
    return None, None

def get_market_block():
    out = {}
    for name, cands in SYMS.items():
        cur = prev = None
        for t in cands:
            cur, prev = _last_two_close_v2(t)
            if cur is not None:
                break
        if cur is None:
            out[name] = {"value": "-", "change": None}
        else:
            chg = None if prev is None or prev == 0 else round((cur - prev) / prev * 100, 2)
            out[name] = {"value": round(cur, 2), "change": chg}
    return out

# -------------------- ë‰´ìŠ¤ (Google News RSS) --------------------
NEWS_QUERIES = [
    "site:mk.co.kr ê²½ì œ",
    "site:hankyung.com ê²½ì œ",
    "site:biz.chosun.com ì‚°ì—…",
    "site:yna.co.kr ì •ì±…",
    "site:policy.go.kr ì •ì±…ë¸Œë¦¬í•‘",
]

def google_rss(query: str) -> str:
    return f"https://news.google.com/rss/search?q={quote(query)}&hl=ko&gl=KR&ceid=KR:ko"

def fetch_headlines_top10() -> List[Dict[str, str]]:
    items: List[Dict[str, str]] = []
    for q in NEWS_QUERIES:
        url = google_rss(q)
        try:
            feed = feedparser.parse(url)
            for e in feed.entries[:8]:  # ì¶œì²˜ë‹¹ 8ê±´
                n = normalize_item(e)
                n["title"] = clean_title(n["title"])
                items.append(n)
        except Exception:
            continue
    # ì¤‘ë³µì œê±°
    clean = []
    seen = set()
    for n in items:
        t, l = n.get("title", ""), n.get("link", "")
        if not t:
            continue
        key = t  # ì œëª© ê¸°ì¤€
        if key in seen:
            continue
        seen.add(key)
        clean.append({"title": t, "link": l})
    return clean[:10]

# -------------------- í…Œë§ˆ ìŠ¤ì½”ì–´ë§ --------------------
# í™•ì¥ ì‚¬ì „: ë™ì˜ì–´/í•˜ìœ„í‚¤ì›Œë“œ ë‹¤ìˆ˜ í¬í•¨
THEMES = {
    "AI": ["AI","ì¸ê³µì§€ëŠ¥","ìƒì„±í˜•","ì±—GPT","LLM","NPU","ì˜¨ë””ë°”ì´ìŠ¤","ì½”íŒŒì¼ëŸ¿","ì—ì´ì•„ì´"],
    "ë°˜ë„ì²´": ["ë°˜ë„ì²´","HBM","GPU","íŒŒìš´ë“œë¦¬","ë©”ëª¨ë¦¬","ë””ë¨","ë‚¸ë“œ","ê³µì •","ë¯¸ì„¸í™”","ì²¨ë‹¨íŒ¨í‚¤ì§•","TSMC","ì—”ë¹„ë””ì•„","í´ëŸ­"],
    "ì´ì°¨ì „ì§€": ["ì´ì°¨ì „ì§€","2ì°¨ì „ì§€","ë°°í„°ë¦¬","ì–‘ê·¹ì¬","ìŒê·¹ì¬","ì „ê³ ì²´","ë¦¬íŠ¬","ë‹ˆì¼ˆ","ì½”ë°œíŠ¸","ì–‘ê·¹","ìŒê·¹"],
    "ë¡œë´‡": ["ë¡œë´‡","íœ´ë¨¸ë…¸ì´ë“œ","ììœ¨ì£¼í–‰","AGV","AMR","í˜‘ë™ë¡œë´‡","ë¡œë³´í‹±ìŠ¤","ë¡œë³´í‹±"],
    "ë°”ì´ì˜¤": ["ë°”ì´ì˜¤","ì œì•½","ì˜ì•½í’ˆ","ì„ìƒ","ì‹ ì•½","FDA","ì¹˜ë£Œì œ","ë°±ì‹ ","í•­ì•”"],
    "ì¡°ì„ ": ["ì¡°ì„ ","ì„ ë°•","í•´ìš´","LNGì„ ","ì»¨í…Œì´ë„ˆì„ ","íƒ±ì»¤","ë“œë¦´ì‹­"],
    "ì›ì „": ["ì›ì „","ì›ìë ¥","SMR","ê°€ì••ê²½ìˆ˜ë¡œ","ì›ì „ìˆ˜ì¶œ","ì›ì „ì •ë¹„"],
    "ì—ë„ˆì§€": ["ì—ë„ˆì§€","ì •ìœ ","ê°€ìŠ¤","ì²œì—°ê°€ìŠ¤","ì¬ìƒì—ë„ˆì§€","íƒœì–‘ê´‘","í’ë ¥","ESS"],
}

REP_STOCKS = {
    "AI": ["ì‚¼ì„±ì „ì","ë„¤ì´ë²„","ì¹´ì¹´ì˜¤","í•œê¸€ê³¼ì»´í“¨í„°","ë”ì¡´ë¹„ì¦ˆì˜¨"],
    "ë°˜ë„ì²´": ["ì‚¼ì„±ì „ì","SKí•˜ì´ë‹‰ìŠ¤","DBí•˜ì´í…","í•œë¯¸ë°˜ë„ì²´","í…ŒìŠ¤"],
    "ì´ì°¨ì „ì§€": ["LGì—ë„ˆì§€ì†”ë£¨ì…˜","í¬ìŠ¤ì½”í“¨ì²˜ì— ","ì—ì½”í”„ë¡œ","ì—ì½”í”„ë¡œë¹„ì— ","ì—˜ì•¤ì—í”„"],
    "ë¡œë´‡": ["ë ˆì¸ë³´ìš°ë¡œë³´í‹±ìŠ¤","ìœ ì§„ë¡œë´‡","í‹°ë¡œë³´í‹±ìŠ¤","ë¡œë³´ìŠ¤íƒ€"],
    "ë°”ì´ì˜¤": ["ì‚¼ì„±ë°”ì´ì˜¤ë¡œì§ìŠ¤","ì…€íŠ¸ë¦¬ì˜¨","ì—ìŠ¤í‹°íŒœ","HLB"],
    "ì¡°ì„ ": ["HDí•œêµ­ì¡°ì„ í•´ì–‘","ì‚¼ì„±ì¤‘ê³µì—…","í•œí™”ì˜¤ì…˜","HDí˜„ëŒ€ë¯¸í¬"],
    "ì›ì „": ["ë‘ì‚°ì—ë„ˆë¹Œë¦¬í‹°","í•œì „KPS","í•œì „ê¸°ìˆ ","ì¼ì§„íŒŒì›Œ"],
    "ì—ë„ˆì§€": ["í•œêµ­ì „ë ¥","ë‘ì‚°ì—ë„ˆë¹Œë¦¬í‹°","GS","SKì´ë…¸ë² ì´ì…˜","í•œêµ­ê°€ìŠ¤ê³µì‚¬"],
}

# í•œê¸€/ì˜ë¬¸ ê³µí†µ ë¶ˆìš©ì–´
STOPWORDS = set("""
ë‹¨ë… ì†ë³´ ì˜ìƒ í¬í†  ì¸í„°ë·° ì‚¬ì„¤ ì¹¼ëŸ¼ ì˜¤í”¼ë‹ˆì–¸ ê¸°ì ì¢…í•© íŠ¹ì§‘
ì˜¤ëŠ˜ ì–´ì œ ë‚´ì¼ ì •ë¶€ ë°œí‘œ íšŒì˜ ê´€ë ¨ ê²€í†  ì¶”ì§„ í™•ì • ì „ë§ ê³„íš
í•œêµ­ê²½ì œ ë§¤ì¼ê²½ì œ í•œê²¨ë ˆ ì¡°ì„ ì¼ë³´ ì¤‘ì•™ì¼ë³´ ì—°í•©ë‰´ìŠ¤ YTN MBC SBS KBS
""".split())

def score_themes(news: List[Dict[str, str]]) -> pd.DataFrame:
    counts = {k: 0 for k in THEMES}
    sample = {k: "" for k in THEMES}
    for raw in news:
        n = normalize_item(raw)
        title = clean_title(n.get("title", ""))
        link = n.get("link", "")
        for th, keys in THEMES.items():
            if any(k in title for k in keys):
                counts[th] += 1
                if not sample[th]:
                    sample[th] = link
    rows = []
    for th, c in counts.items():
        if c > 0:
            rows.append({
                "theme": th,
                "rep_stocks": " Â· ".join(REP_STOCKS.get(th, [])[:5]),
                "count": int(c),
                "sample_link": sample[th],
            })
    if not rows:
        return pd.DataFrame(columns=["theme","rep_stocks","count","sample_link"])
    return pd.DataFrame(rows).sort_values(["count","theme"], ascending=[False,True]).reset_index(drop=True)

def extract_keywords(news: List[Dict[str, str]]) -> pd.DataFrame:
    bag: Dict[str, int] = {}
    for raw in news:
        n = normalize_item(raw)
        title = clean_title(n.get("title", ""))
        # í† í°í™”
        for w in re.findall(r"[ê°€-í£A-Za-z0-9]+", title):
            if len(w) < 2:
                continue
            if w in STOPWORDS:
                continue
            if re.fullmatch(r"\d+", w):
                continue
            bag[w] = bag.get(w, 0) + 1
    if not bag:
        return pd.DataFrame(columns=["keyword","count"])
    top = sorted(bag.items(), key=lambda x: x[1], reverse=True)[:30]
    return pd.DataFrame(top, columns=["keyword","count"])

# -------------------- ë°ì´í„° ë§Œë“¤ê¸° --------------------
market = get_market_block()
headlines = fetch_headlines_top10()
themes_df = score_themes(headlines)
keywords_df = extract_keywords(headlines)

# -------------------- UI --------------------
def metric(col, title, obj):
    val, chg = obj["value"], obj["change"]
    if val == "-":
        col.metric(title, value="-", delta="None")
    else:
        col.metric(title, value=f"{val:,.2f}", delta=("None" if chg is None else f"{chg:+.2f}%"))

st.subheader("ğŸ“Š ì˜¤ëŠ˜ì˜ ì‹œì¥ ìš”ì•½")
c1, c2, c3 = st.columns(3)
c4, c5, c6 = st.columns(3)
metric(c1, "KOSPI", market["KOSPI"])
metric(c2, "KOSDAQ", market["KOSDAQ"])
metric(c3, "í™˜ìœ¨(USD/KRW)", market["USDKRW"])
metric(c4, "WTI", market["WTI"])
metric(c5, "Gold", market["Gold"])
metric(c6, "Copper", market["Copper"])

st.divider()
st.subheader("ğŸ“° ìµœì‹  ê²½ì œÂ·ì •ì±…Â·ì‚°ì—…Â·ë¦¬í¬íŠ¸ ë‰´ìŠ¤ TOP 10")
if not headlines:
    st.info("í—¤ë“œë¼ì¸ ì—†ìŒ")
else:
    for i, n in enumerate(headlines, start=1):
        n = normalize_item(n)
        t, l = n.get("title",""), n.get("link","")
        st.markdown(f"{i}. " + (f"[{t}]({l})" if l else t))

st.divider()
st.subheader("ğŸ”¥ ë‰´ìŠ¤ ê¸°ë°˜ TOP í…Œë§ˆ")
if themes_df.empty:
    st.info("í…Œë§ˆ ë°ì´í„° ì—†ìŒ")
else:
    st.bar_chart(themes_df.set_index("theme")["count"])
    st.dataframe(themes_df, use_container_width=True)

st.divider()
st.subheader("ğŸŒ ì›”ê°„ í‚¤ì›Œë“œë§µ (ìµœê·¼ 30ì¼)")
if keywords_df.empty:
    st.info("í‚¤ì›Œë“œ ì—†ìŒ")
else:
    st.bar_chart(keywords_df.set_index("keyword")["count"])

st.success("âœ… ëŒ€ì‹œë³´ë“œ ë¡œë”© ì™„ë£Œ (ì§€ìˆ˜ ë°±ì—…ì‹¬ë³¼/ë¶ˆìš©ì–´/í™•ì¥ì‚¬ì „ ì ìš©)")
