# -*- coding: utf-8 -*-
# app.py
import math, re
from datetime import datetime, timedelta, date
from zoneinfo import ZoneInfo
from urllib.parse import quote_plus
from collections import Counter

import numpy as np
import pandas as pd
import streamlit as st
import yfinance as yf
import feedparser
from bs4 import BeautifulSoup
from sklearn.linear_model import LogisticRegression

KST = ZoneInfo("Asia/Seoul")

# =========================
# ê³µí†µ ì„¤ì • & ìœ í‹¸
# =========================
st.set_page_config(page_title="AI ë‰´ìŠ¤ë¦¬í¬íŠ¸ â€“ ìë™ í…Œë§ˆÂ·ì‹œì„¸ ì˜ˆì¸¡", layout="wide")

def now_kst():
    return datetime.now(KST).strftime("%Y-%m-%d %H:%M:%S (KST)")

def fmt_number(v, d=2):
    try:
        if v is None or (isinstance(v, float) and (math.isnan(v) or math.isinf(v))):
            return "-"
        return f"{v:,.{d}f}"
    except Exception:
        return "-"

def fmt_percent(v):
    try:
        if v is None or (isinstance(v, float) and (math.isnan(v) or math.isinf(v))):
            return "-"
        return f"{v:+.2f}%"
    except Exception:
        return "-"

def valid_prices(last, prev):
    return last is not None and prev not in (None, 0) and all(map(np.isfinite, [last, prev]))

# =========================
# ì‹œì„¸ ìˆ˜ì§‘ (ì•ˆì •í˜•)
# =========================
@st.cache_data(ttl=600)
def fetch_quote(ticker: str):
    # 1) fast_info
    try:
        t = yf.Ticker(ticker)
        last = getattr(t.fast_info, "last_price", None)
        prev = getattr(t.fast_info, "previous_close", None)
        if valid_prices(last, prev):
            return float(last), float(prev)
    except Exception:
        pass
    # 2) ìµœê·¼ 7ì¼ ì¢…ê°€
    try:
        df = yf.download(ticker, period="7d", interval="1d", auto_adjust=False, progress=False)
        closes = df.get("Close")
        if closes is None:
            return None, None
        closes = closes.dropna()
        if len(closes) == 0:
            return None, None
        last = float(closes.iloc[-1])
        prev = float(closes.iloc[-2]) if len(closes) >= 2 else None
        return last, prev
    except Exception:
        return None, None

# =========================
# ë‰´ìŠ¤ (Google RSS)
# =========================
def clean_html(raw): return BeautifulSoup(raw or "", "html.parser").get_text(" ", strip=True)

def _parse_entries(feed, days):
    now = datetime.now(KST)
    out = []
    for e in feed.entries:
        pub = None
        if getattr(e, "published_parsed", None):
            pub = datetime(*e.published_parsed[:6], tzinfo=KST)
        elif getattr(e, "updated_parsed", None):
            pub = datetime(*e.updated_parsed[:6], tzinfo=KST)
        if pub and (now - pub) > timedelta(days=days):
            continue
        title = getattr(e, "title", "").strip()
        link = getattr(e, "link", "").strip()
        if link.startswith("./"):
            link = "https://news.google.com/" + link[2:]
        desc = clean_html(getattr(e, "summary", ""))
        out.append({"title": title, "link": link,
                    "time": pub.strftime("%Y-%m-%d %H:%M") if pub else "-",
                    "desc": desc})
    return out

@st.cache_data(ttl=600)
def fetch_google_news_by_keyword(keyword, days=3, limit=50):
    q = quote_plus(keyword)
    url = f"https://news.google.com/rss/search?q={q}&hl=ko&gl=KR&ceid=KR%3Ako"
    feed = feedparser.parse(url, request_headers={"User-Agent": "Mozilla/5.0"})
    return _parse_entries(feed, days)[:limit]

CATEGORIES = {
    "ê²½ì œë‰´ìŠ¤": ["ê²½ì œ","ê¸ˆë¦¬","ë¬¼ê°€","í™˜ìœ¨","ì„±ì¥ë¥ ","ë¬´ì—­"],
    "ì£¼ì‹ë‰´ìŠ¤": ["ì½”ìŠ¤í”¼","ì½”ìŠ¤ë‹¥","ì¦ì‹œ","ì£¼ê°€","ì™¸êµ­ì¸ ë§¤ìˆ˜","ê¸°ê´€ ë§¤ë„"],
    "ì‚°ì—…ë‰´ìŠ¤": ["ë°˜ë„ì²´","AI","ë°°í„°ë¦¬","ìë™ì°¨","ë¡œë´‡","ìˆ˜ì¶œì…","ì „ë ¥","ì „ê¸°ìš”ê¸ˆ","ì „ë ¥ìˆ˜ê¸‰"],
    "ì •ì±…ë‰´ìŠ¤": ["ì •ì±…","ì •ë¶€","ì˜ˆì‚°","ê·œì œ","ì„¸ê¸ˆ","ì‚°ì—…ë¶€"],
}

@st.cache_data(ttl=600)
def fetch_category_news(cat, days=3, max_items=120):
    seen, out = set(), []
    for kw in CATEGORIES.get(cat, []):
        try:
            for it in fetch_google_news_by_keyword(kw, days):
                k = (it["title"], it["link"])
                if k in seen: 
                    continue
                seen.add(k)
                out.append(it)
        except Exception:
            continue
    def _key(x):
        try: return datetime.strptime(x["time"], "%Y-%m-%d %H:%M")
        except: return datetime.min
    out.sort(key=_key, reverse=True)
    return out[:max_items]

# =========================
# í‹°ì»¤ë°”
# =========================
TICKER_CSS = """
<style>
.ticker-wrap{position:relative;overflow:hidden;width:100%;border:1px solid #263042;border-radius:10px;background:#0f1420;}
.ticker-track{display:flex;gap:12px;align-items:center;width:max-content;will-change:transform;
  animation:ticker-scroll var(--speed,32s) linear infinite;}
@keyframes ticker-scroll{0%{transform:translateX(0);}100%{transform:translateX(-50%);}}
.badge{display:inline-flex;align-items:center;gap:6px;background:#0f1420;border:1px solid #2b3a55;
  color:#c7d2fe;padding:4px 8px;border-radius:8px;font-weight:700;white-space:nowrap;font-size:0.9rem}
.badge .name{color:#9fb3c8;font-weight:600;}
.badge .up{color:#e66;} .badge .down{color:#6aa2ff;} .sep{color:#44526b;padding:0 4px;}
.small-cap{font-size:.85rem;color:#9aa0a6}
.card-grid{display:grid;grid-template-columns:repeat(4,1fr);gap:10px;margin:8px 0 18px}
.stock-card{border:1px solid #263042;border-radius:10px;padding:10px;background:#0f1420}
.stock-card .nm{font-weight:700}
.stock-card .px{margin-top:3px}
.stock-card .px.up{color:#e66}
.stock-card .px.down{color:#6aa2ff}
.stock-card .px.flat{color:#a3aab8}
@media (max-width: 1000px){.card-grid{grid-template-columns:repeat(2,1fr)}}
.quick-menu{position:fixed;right:8px;top:90px;z-index:9999;width:170px}
.quick-menu .box{background:#0f1420;border:1px solid #2b3a55;border-radius:14px;padding:8px}
.quick-menu a{display:flex;align-items:center;gap:6px;font-size:.86rem;padding:6px 8px;margin:4px 0;
  border:1px solid #283652;border-radius:10px;text-decoration:none;color:#dbe6ff}
.quick-menu a:hover{background:#12223b}
.quick-title{font-size:.9rem;color:#98a6be;margin:2px 0 8px 2px}
.section-h{scroll-margin-top:70px;}
.compact-item{margin-bottom:.45rem}
.compact-item .when{color:#9aa0a6;font-size:.85rem}
</style>
"""
st.markdown(TICKER_CSS, unsafe_allow_html=True)

def build_ticker_items():
    rows=[("KOSPI","^KS11",2),("KOSDAQ","^KQ11",2),
          ("DOW","^DJI",2),("NASDAQ","^IXIC",2),
          ("USD/KRW","KRW=X",2),("WTI","CL=F",2),
          ("Gold","GC=F",2),("Copper","HG=F",3)]
    items=[]
    for name,ticker,dp in rows:
        last, prev = fetch_quote(ticker)
        d=p=None
        if valid_prices(last, prev):
            d = last - prev
            p = (d/prev)*100
        items.append({"name":name,"last":fmt_number(last,dp),
                      "pct":fmt_percent(p) if p is not None else "--",
                      "is_up":(d or 0)>0,"is_down":(d or 0)<0})
    return items

def render_ticker_line(items, speed_sec=32):
    chips=[]
    for it in items:
        arrow="â–²" if it["is_up"] else ("â–¼" if it["is_down"] else "â€¢")
        cls="up" if it["is_up"] else ("down" if it["is_down"] else "")
        chips.append(f"<span class='badge'><span class='name'>{it['name']}</span>{it['last']} <span class='{cls}'>{arrow} {it['pct']}</span></span>")
    line='<span class="sep">|</span>'.join(chips)
    st.markdown(f"<div class='ticker-wrap'><div class='ticker-track' style='--speed:{speed_sec}s'>{line}<span class='sep'>|</span>{line}</div></div>", unsafe_allow_html=True)

# =========================
# í—¤ë” + í€µ ë©”ë‰´(ì‘ê²Œ)
# =========================
st.markdown(f"#### ğŸ§  AI ë‰´ìŠ¤ë¦¬í¬íŠ¸ â€” ì—…ë°ì´íŠ¸: {now_kst()}")
rc1, rc2 = st.columns([1,5])
with rc1: st.markdown("### ğŸ“Š ì˜¤ëŠ˜ì˜ ì‹œì¥ ìš”ì•½")
with rc2:
    if st.button("ğŸ”„ ìƒˆë¡œê³ ì¹¨", use_container_width=False):
        st.cache_data.clear()
        st.rerun()
render_ticker_line(build_ticker_items())

# ì‘ì€ í€µë©”ë‰´
quick = """
<div class="quick-menu">
  <div class="box">
    <div class="quick-title">Quick Menu</div>
    <a href="#sec-news">ğŸ“° ìµœì‹  ìš”ì•½</a>
    <a href="#sec-theme">ğŸ”¥ í…Œë§ˆ ìš”ì•½</a>
    <a href="#sec-engine">ğŸ§  ìš”ì•½ì—”ì§„</a>
    <a href="#sec-prob">ğŸ“Š ìƒìŠ¹ í™•ë¥ </a>
    <a href="#sec-top">ğŸš€ Top5</a>
    <a href="#sec-3d">ğŸ”® 3ì¼ ì˜ˆì¸¡</a>
    <a href="#sec-admin">ğŸ›  í…Œë§ˆ ê´€ë¦¬ì</a>
  </div>
</div>
"""
st.markdown(quick, unsafe_allow_html=True)

st.caption("â€» ìƒìŠ¹=ë¹¨ê°•, í•˜ë½=íŒŒë‘ Â· ê°€ê²©: Yahoo Finance (ì§€ì—° ê°€ëŠ¥)")

# =========================
# ìµœì‹  ë‰´ìŠ¤ (ì œëª© + ì‹œê°„, ì»´íŒ©íŠ¸)
# =========================
st.markdown('<div id="sec-news" class="section-h"></div>', unsafe_allow_html=True)
st.divider()
st.markdown("## ğŸ“° ìµœì‹  ë‰´ìŠ¤ ìš”ì•½")

c1, c2 = st.columns([2,1])
with c1: cat = st.selectbox("ğŸ“‚ ì¹´í…Œê³ ë¦¬", list(CATEGORIES))
with c2: page = st.number_input("í˜ì´ì§€", 1, 99, 1, 1)
news_all = fetch_category_news(cat, days=3, max_items=120)

pg_size = 10
start = (page-1)*pg_size
chunk = news_all[start:start+pg_size]

if not chunk:
    st.info("í‘œì‹œí•  ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
else:
    for it in chunk:
        st.markdown(
            f"<div class='compact-item'>"
            f"<a href='{it['link']}' target='_blank'><b>{it['title']}</b></a><br>"
            f"<span class='when'>{it['time']}</span>"
            f"</div>",
            unsafe_allow_html=True
        )
st.caption(f"ìµœê·¼ 3ì¼ Â· {cat} Â· {len(news_all)}ê±´ ì¤‘ {start+1}-{min(start+pg_size, len(news_all))} í‘œì‹œ")

# =========================
# í…Œë§ˆ í‚¤ì›Œë“œ & ëŒ€í‘œ ì¢…ëª© ë§µ
# =========================
THEME_KEYWORDS = {
    "AI":["ai","ì¸ê³µì§€ëŠ¥","ì±—ë´‡","ì—”ë¹„ë””ì•„","ì˜¤í”ˆai","ìƒì„±í˜•"],
    "ë°˜ë„ì²´":["ë°˜ë„ì²´","hbm","ì¹©","ë¨","íŒŒìš´ë“œë¦¬"],
    "ë¡œë´‡":["ë¡œë´‡","ììœ¨ì£¼í–‰","í˜‘ë™ë¡œë´‡","amr"],
    "ì´ì°¨ì „ì§€":["ë°°í„°ë¦¬","ì „ê³ ì²´","ì–‘ê·¹ì¬","ìŒê·¹ì¬","lfp"],
    "ì—ë„ˆì§€":["ì—ë„ˆì§€","ì •ìœ ","ì „ë ¥","íƒœì–‘ê´‘","í’ë ¥","ê°€ìŠ¤"],
    "ì¡°ì„ ":["ì¡°ì„ ","ì„ ë°•","lngì„ ","í•´ìš´"],
    "LNG":["lng","ê°€ìŠ¤ê³µì‚¬","í„°ë¯¸ë„"],
    "ì›ì „":["ì›ì „","smr","ì›ìë ¥","ìš°ë¼ëŠ„"],
    "ë°”ì´ì˜¤":["ë°”ì´ì˜¤","ì œì•½","ì‹ ì•½","ì„ìƒ"],
}
THEME_STOCKS = {
    "AI":[("ì‚¼ì„±ì „ì","005930.KS"),("ë„¤ì´ë²„","035420.KS"),("ì¹´ì¹´ì˜¤","035720.KS"),
          ("ì†”íŠ¸ë£©ìŠ¤","304100.KQ"),("ë¸Œë ˆì¸ì¦ˆì»´í¼ë‹ˆ","099390.KQ"),("í•œê¸€ê³¼ì»´í“¨í„°","030520.KS")],
    "ë°˜ë„ì²´":[("SKí•˜ì´ë‹‰ìŠ¤","000660.KS"),("DBí•˜ì´í…","000990.KS"),("ë¦¬ë…¸ê³µì—…","058470.KQ"),
          ("ì›ìµIPS","240810.KQ"),("í‹°ì”¨ì¼€ì´","064760.KQ"),("ì—í”„ì—ìŠ¤í‹°","036810.KQ")],
    "ë¡œë´‡":[("ë ˆì¸ë³´ìš°ë¡œë³´í‹±ìŠ¤","277810.KQ"),("ìœ ì§„ë¡œë´‡","056080.KQ"),("í‹°ë¡œë³´í‹±ìŠ¤","117730.KQ"),
          ("ë¡œë³´ìŠ¤íƒ€","090360.KQ"),("ìŠ¤ë§¥","099440.KQ")],
    "ì´ì°¨ì „ì§€":[("LGì—ë„ˆì§€ì†”ë£¨ì…˜","373220.KS"),("í¬ìŠ¤ì½”í“¨ì²˜ì— ","003670.KS"),
          ("ì—ì½”í”„ë¡œ","086520.KQ"),("ì½”ìŠ¤ëª¨ì‹ ì†Œì¬","005070.KQ"),("ì—˜ì•¤ì—í”„","066970.KQ")],
    "ì—ë„ˆì§€":[("í•œêµ­ì „ë ¥","015760.KS"),("ë‘ì‚°ì—ë„ˆë¹Œë¦¬í‹°","034020.KS"),
          ("GS","078930.KS"),("í•œí™”ì†”ë£¨ì…˜","009830.KS"),("OCIí™€ë”©ìŠ¤","010060.KS")],
    "ì¡°ì„ ":[("HDí•œêµ­ì¡°ì„ í•´ì–‘","009540.KS"),("HDí˜„ëŒ€ë¯¸í¬","010620.KS"),
          ("ì‚¼ì„±ì¤‘ê³µì—…","010140.KS"),("í•œí™”ì˜¤ì…˜","042660.KS")],
    "LNG":[("í•œêµ­ê°€ìŠ¤ê³µì‚¬","036460.KS"),("ì§€ì—ìŠ¤ì´","053050.KQ"),("ëŒ€ì„±ì—ë„ˆì§€","117580.KQ"),("SKê°€ìŠ¤","018670.KS")],
    "ì›ì „":[("ë‘ì‚°ì—ë„ˆë¹Œë¦¬í‹°","034020.KS"),("ìš°ì§„","105840.KQ"),("í•œì „KPS","051600.KS"),("ë³´ì„±íŒŒì›Œí…","006910.KQ")],
    "ë°”ì´ì˜¤":[("ì…€íŠ¸ë¦¬ì˜¨","068270.KS"),("ì—ìŠ¤í‹°íŒœ","237690.KQ"),("ì•Œí…Œì˜¤ì  ","196170.KQ"),("ë©”ë””í†¡ìŠ¤","086900.KQ")],
}

# =========================
# ë‰´ìŠ¤ ê¸°ë°˜ í…Œë§ˆ ìš”ì•½ (ì˜¤ë¥˜ ìˆ˜ì • ë²„ì „)
# =========================
st.markdown('<div id="sec-theme" class="section-h"></div>', unsafe_allow_html=True)
st.divider()
st.markdown("## ğŸ”¥ ë‰´ìŠ¤ ê¸°ë°˜ í…Œë§ˆ ìš”ì•½")

def detect_themes_hybrid(news_list, theme_kws:dict, price_boost=True, pct_threshold=2.0, min_stocks=2):
    counts = {t: 0 for t in theme_kws}
    sample = {t: "" for t in theme_kws}

    for n in news_list:
        text = (n.get("title","") + " " + n.get("desc","")).lower()
        for t, kws in theme_kws.items():
            if any(k in text for k in kws):
                counts[t] += 1
                if not sample[t]:
                    sample[t] = n.get("link","")

    price_info = {}
    for theme, stocks in THEME_STOCKS.items():
        deltas = []
        for _, tk in stocks:
            last, prev = fetch_quote(tk)
            if valid_prices(last, prev):
                deltas.append((last - prev) / prev * 100.0)
        avg_delta = float(np.mean(deltas)) if deltas else 0.0
        up_cnt = int(sum(d > 0 for d in deltas))
        price_info[theme] = (avg_delta, up_cnt)
        if price_boost and avg_delta >= pct_threshold and up_cnt >= min_stocks:
            counts[theme] = max(counts.get(theme, 0), 1)

    rows = []
    all_themes = set(theme_kws.keys()) | set(THEME_STOCKS.keys())
    for theme in all_themes:
        c = int(counts.get(theme, 0))
        avg_delta, up_cnt = price_info.get(theme, (0.0, 0))
        if c > 0 or (price_boost and avg_delta >= pct_threshold and up_cnt >= min_stocks):
            driver = ("ê°€ê²© ì£¼ë„" if (c == 0 and avg_delta >= pct_threshold and up_cnt >= min_stocks)
                      else ("ë‰´ìŠ¤+ê°€ê²©" if (c > 0 and avg_delta >= pct_threshold) else
                            ("ë‰´ìŠ¤ ì£¼ë„" if c > 0 else "ê°€ê²© ì£¼ë„")))
            rows.append({
                "í…Œë§ˆ": theme,
                "ë‰´ìŠ¤ê±´ìˆ˜": c,
                "í‰ê· ë“±ë½(%)": round(avg_delta, 2),
                "ìƒìŠ¹ì¢…ëª©ìˆ˜": int(up_cnt),
                "ì£¼ë„ìš”ì¸": driver,
                "ìƒ˜í”Œë§í¬": sample.get(theme, "") or "",
                "ëŒ€í‘œì¢…ëª©": " Â· ".join([nm for nm, _ in THEME_STOCKS.get(theme, [])]) or "-",
            })
    rows.sort(key=lambda x: (x["ë‰´ìŠ¤ê±´ìˆ˜"], x["í‰ê· ë“±ë½(%)"]), reverse=True)
    return rows

# ì˜¬ë°”ë¥´ê²Œ ë‰´ìŠ¤ í•©ì¹˜ê¸° (NULL ì¶œë ¥ ë°©ì§€)
news_cache = {k: fetch_category_news(k, 3, 120) for k in CATEGORIES}
all_news = []
for v in news_cache.values():
    all_news.extend(v)

theme_rows = detect_themes_hybrid(all_news, THEME_KEYWORDS, True, 2.0, 2)

if not theme_rows:
    st.info("ìµœê·¼ 3ì¼ ê¸°ì¤€ í…Œë§ˆ ì‹ í˜¸ê°€ ì•½í•©ë‹ˆë‹¤.")
else:
    df_theme = pd.DataFrame(theme_rows)
    df_view = df_theme.copy()
    df_view["ìƒ˜í”Œ ë‰´ìŠ¤"] = df_view["ìƒ˜í”Œë§í¬"]

    try:
        st.dataframe(
            df_view[["í…Œë§ˆ","ë‰´ìŠ¤ê±´ìˆ˜","í‰ê· ë“±ë½(%)","ìƒìŠ¹ì¢…ëª©ìˆ˜","ì£¼ë„ìš”ì¸","ëŒ€í‘œì¢…ëª©","ìƒ˜í”Œ ë‰´ìŠ¤"]],
            use_container_width=True, hide_index=True,
            column_config={"ìƒ˜í”Œ ë‰´ìŠ¤": st.column_config.LinkColumn("ìƒ˜í”Œ ë‰´ìŠ¤", display_text="ì—´ê¸°")}
        )
    except Exception:
        st.dataframe(df_view, use_container_width=True, hide_index=True)
        st.caption("â€» â€˜ìƒ˜í”Œ ë‰´ìŠ¤â€™ ì»¬ëŸ¼ì˜ URLì„ í´ë¦­í•´ ì—´ì–´ì£¼ì„¸ìš”.")

    st.markdown("### ğŸ§© ëŒ€í‘œ ì¢…ëª© ì‹œì„¸ (ìƒìŠ¹=ë¹¨ê°• / í•˜ë½=íŒŒë‘)")
    def rep_price(tk):
        last, prev = fetch_quote(tk)
        if not valid_prices(last, prev): return None, None, "flat"
        delta = (last - prev) / prev * 100
        tone = "up" if delta > 0 else ("down" if delta < 0 else "flat")
        return fmt_number(last, 0), fmt_percent(delta), tone

    for tr in df_theme.head(5).to_dict("records"):
        theme = tr["í…Œë§ˆ"]
        stocks = THEME_STOCKS.get(theme, [])[:6]
        if not stocks: 
            continue
        st.markdown(
            f"**{theme}** â€” "
            f"<span class='small-cap'>ì£¼ë„: {tr['ì£¼ë„ìš”ì¸']} Â· í‰ê· ë“±ë½ {tr['í‰ê· ë“±ë½(%)']}%</span>",
            unsafe_allow_html=True
        )
        cards=[]
        for nm, tk in stocks:
            px, chg, tone = rep_price(tk)
            arrow = "â–²" if tone=="up" else ("â–¼" if tone=="down" else "â– ")
            html = (f"<div class='stock-card'><div class='nm'>{nm}</div>"
                    f"<div class='ticker'>{tk}</div>"
                    f"<div class='px {tone}'>{px if px else '-'} {arrow if px else ''} {chg if px else ''}</div></div>")
            cards.append(html)
        st.markdown(f"<div class='card-grid'>{''.join(cards)}</div>", unsafe_allow_html=True)

# =========================
# AI ë‰´ìŠ¤ ìš”ì•½ì—”ì§„ (ë”ë³´ê¸°)
# =========================
st.markdown('<div id="sec-engine" class="section-h"></div>', unsafe_allow_html=True)
st.divider()
st.markdown("## ğŸ§  AI ë‰´ìŠ¤ ìš”ì•½ì—”ì§„")
titles = [n["title"] for n in all_news]
words=[]
for t in titles:
    t = re.sub(r"[^ê°€-í£A-Za-z0-9\s]"," ",t)
    words += [w for w in t.split() if len(w)>=2]
top_kw = [w for w,_ in Counter(words).most_common(10)]
st.markdown("### ğŸ“Œ í•µì‹¬ í‚¤ì›Œë“œ TOP10")
st.write(", ".join(top_kw) if top_kw else "ë°ì´í„° ë¶€ì¡±")

full_text = " ".join([n.get("title","")+" "+n.get("desc","") for n in all_news])
sentences = [s for s in re.split(r'[.!?]\s+', full_text) if len(s.strip())>20][:5]
st.markdown("### ğŸ“° í•µì‹¬ ìš”ì•½ë¬¸")
if sentences:
    st.markdown(f"**ìš”ì•½:** {sentences[0][:150]}...")
    with st.expander("ì „ì²´ ìš”ì•½ë¬¸ ë³´ê¸° ğŸ‘‡"):
        for s in sentences: st.markdown(f"- {s.strip()}")
else:
    st.info("ìš”ì•½ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

# =========================
# AI ìƒìŠ¹ í™•ë¥  ë¦¬í¬íŠ¸
# =========================
st.markdown('<div id="sec-prob" class="section-h"></div>', unsafe_allow_html=True)
st.divider()
st.markdown("## ğŸ“Š AI ìƒìŠ¹ í™•ë¥  ì˜ˆì¸¡ ë¦¬í¬íŠ¸")

def calc_theme_strength(count, avg_delta):
    freq = min(count/20, 1.0)
    prc = min(max((avg_delta+5)/10, 0), 1.0)
    return round((freq*0.6 + prc*0.4)*5, 1)

def calc_risk_level(avg_delta):
    if avg_delta >= 3: return 1
    if avg_delta >= 1: return 2
    if avg_delta >= -1: return 3
    if avg_delta >= -3: return 4
    return 5

report=[]
for tr in theme_rows[:5]:
    theme = tr["í…Œë§ˆ"]
    deltas=[]
    for _, tk in THEME_STOCKS.get(theme, []):
        last, prev = fetch_quote(tk)
        if valid_prices(last, prev):
            deltas.append((last-prev)/prev*100)
    avg_delta = float(np.mean(deltas)) if deltas else 0.0
    report.append({
        "í…Œë§ˆ": theme,
        "ë‰´ìŠ¤ê±´ìˆ˜": tr["ë‰´ìŠ¤ê±´ìˆ˜"],
        "í‰ê· ë“±ë½(%)": round(avg_delta,2),
        "í…Œë§ˆê°•ë„(1~5)": calc_theme_strength(tr["ë‰´ìŠ¤ê±´ìˆ˜"], avg_delta),
        "ë¦¬ìŠ¤í¬ë ˆë²¨(1~5)": calc_risk_level(avg_delta)
    })

st.dataframe(pd.DataFrame(report), use_container_width=True, hide_index=True)
st.caption("â€» í…Œë§ˆê°•ë„â†‘ = ë‰´ìŠ¤+ê°€ê²© í™œë°œ / ë¦¬ìŠ¤í¬ë ˆë²¨â†‘ = ë³€ë™ì„±Â·í•˜ë½ ê°€ëŠ¥ì„± ë†’ìŒ")

# =========================
# ìœ ë§ ì¢…ëª© Top5
# =========================
st.markdown('<div id="sec-top" class="section-h"></div>', unsafe_allow_html=True)
st.divider()
st.markdown("## ğŸš€ ì˜¤ëŠ˜ì˜ AI ìœ ë§ ì¢…ëª© Top5")

def pick_promising_stocks(theme_rows, top_n=5):
    cands=[]
    for tr in theme_rows[:8]:
        theme = tr["í…Œë§ˆ"]
        for name, tk in THEME_STOCKS.get(theme, []):
            last, prev = fetch_quote(tk)
            if not valid_prices(last, prev): 
                continue
            delta = (last-prev)/prev*100
            score = tr["ë‰´ìŠ¤ê±´ìˆ˜"]*0.3 + delta*0.7
            cands.append({"í…Œë§ˆ":theme,"ì¢…ëª©ëª…":name,"í‹°ì»¤":tk,
                          "ë“±ë½ë¥ (%)":round(delta,2),"ë‰´ìŠ¤ë¹ˆë„":tr["ë‰´ìŠ¤ê±´ìˆ˜"],"AIì ìˆ˜":round(score,2)})
    df = pd.DataFrame(cands)
    return df.sort_values("AIì ìˆ˜", ascending=False).head(top_n) if not df.empty else df

recommend_df = pick_promising_stocks(theme_rows, 5)
if recommend_df.empty:
    st.info("ì¶”ì²œí•  ì¢…ëª©ì´ ì—†ìŠµë‹ˆë‹¤.")
else:
    st.dataframe(recommend_df, use_container_width=True, hide_index=True)
    st.markdown("### ğŸ§¾ AI ì¢…í•© íŒë‹¨")
    for _, r in recommend_df.iterrows():
        emoji = "ğŸ”º" if r["ë“±ë½ë¥ (%)"]>0 else "ğŸ”»"
        st.markdown(f"- **{r['ì¢…ëª©ëª…']} ({r['í‹°ì»¤']})** â€” í…Œë§ˆ: *{r['í…Œë§ˆ']}*, "
                    f"ë“±ë½ë¥  **{r['ë“±ë½ë¥ (%)']}%**, ë‰´ìŠ¤ë¹ˆë„ {r['ë‰´ìŠ¤ë¹ˆë„']}ê±´, AIì ìˆ˜ {r['AIì ìˆ˜']}")

# =========================
# 3ì¼ ì˜ˆì¸¡ ëª¨ë“ˆ
# =========================
st.markdown('<div id="sec-3d" class="section-h"></div>', unsafe_allow_html=True)
st.divider()
st.markdown("## ğŸ”® AI 3ì¼ ì˜ˆì¸¡: ë‚´ì¼ ì˜¤ë¥¼ í™•ë¥ ")

@st.cache_data(ttl=600)
def load_hist(ticker: str, period="2y"):
    df = yf.download(ticker, period=period, interval="1d", auto_adjust=True, progress=False)
    return df[~df.index.duplicated(keep='last')].dropna()

def rsi(series: pd.Series, period: int = 14):
    delta = series.diff()
    up = np.where(delta > 0, delta, 0.0)
    down = np.where(delta < 0, -delta, 0.0)
    roll_up = pd.Series(up, index=series.index).rolling(period).mean()
    roll_down = pd.Series(down, index=series.index).rolling(period).mean().replace(0, np.nan)
    rs = roll_up / roll_down
    r = 100 - (100 / (1 + rs))
    return r.fillna(50)

def macd(series: pd.Series, fast=12, slow=26, signal=9):
    ema_f = series.ewm(span=fast, adjust=False).mean()
    ema_s = series.ewm(span=slow, adjust=False).mean()
    line = ema_f - ema_s
    sig = line.ewm(span=signal, adjust=False).mean()
    hist = line - sig
    return line, sig, hist

def build_features(df: pd.DataFrame):
    price = df["Close"]
    feat = pd.DataFrame(index=df.index)
    feat["ret_1d"] = price.pct_change(1)
    feat["ret_5d"] = price.pct_change(5)
    feat["ret_10d"] = price.pct_change(10)
    feat["vol_5d"] = price.pct_change().rolling(5).std()
    feat["vol_20d"] = price.pct_change().rolling(20).std()
    feat["rsi_14"] = rsi(price, 14)
    m, s, h = macd(price)
    feat["macd"] = m; feat["macd_sig"] = s; feat["macd_hist"] = h
    ma5 = price.rolling(5).mean(); ma20 = price.rolling(20).mean()
    feat["ma5_gap"] = (price-ma5)/ma5
    feat["ma20_gap"] = (price-ma20)/ma20
    y = (price.shift(-1) > price).astype(int)
    return pd.concat([feat, y.rename("y")], axis=1).dropna()

def fit_predict_prob(df_feat: pd.DataFrame):
    if len(df_feat) < 120: return None, None
    data = df_feat.tail(300)
    X = data.drop(columns=["y"]).values
    y = data["y"].values
    n = len(data); split = max(60, n-3)
    X_train, y_train = X[:split], y[:split]
    X_pred = X[split:]
    model = LogisticRegression(max_iter=300, n_jobs=None)
    model.fit(X_train, y_train)
    prob = model.predict_proba(X_pred)[:,1]
    p1 = float(prob[0]) if len(prob)>0 else None
    p3 = float(prob.mean()) if len(prob)>0 else None
    return p1, p3

rows=[]
if recommend_df.empty:
    st.info("ë¨¼ì € Top5ê°€ ìƒì„±ë˜ì–´ì•¼ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆì–´ìš”.")
else:
    with st.spinner("ì˜ˆì¸¡ ê³„ì‚° ì¤‘..."):
        for _, r in recommend_df.iterrows():
            name, tk = r["ì¢…ëª©ëª…"], r["í‹°ì»¤"]
            try:
                hist = load_hist(tk)
                feats = build_features(hist)
                p1, p3 = fit_predict_prob(feats)
                if p1 is None:
                    rows.append({"ì¢…ëª©ëª…":name,"í‹°ì»¤":tk,"ë‚´ì¼ìƒìŠ¹í™•ë¥ ":"-","3ì¼í‰ê· í™•ë¥ ":"-","ì‹ í˜¸":"ë°ì´í„°ë¶€ì¡±"})
                else:
                    sig = "ë§¤ìˆ˜ê´€ì‹¬" if p1>=0.55 else ("ê´€ë§" if p1>=0.45 else "ì£¼ì˜")
                    rows.append({"ì¢…ëª©ëª…":name,"í‹°ì»¤":tk,"ë‚´ì¼ìƒìŠ¹í™•ë¥ ":round(p1*100,1),
                                 "3ì¼í‰ê· í™•ë¥ ":round(p3*100,1),"ì‹ í˜¸":sig})
            except Exception:
                rows.append({"ì¢…ëª©ëª…":name,"í‹°ì»¤":tk,"ë‚´ì¼ìƒìŠ¹í™•ë¥ ":"-","3ì¼í‰ê· í™•ë¥ ":"-","ì‹ í˜¸":"ì˜¤ë¥˜"})

pred_df = pd.DataFrame(rows)
if not pred_df.empty:
    def _prob_color(v):
        try: v=float(v)
        except: return ""
        if v>=60: return "background-color: rgba(217,48,37,.18); color:#ffd2cf; font-weight:700;"
        if v>=50: return "background-color: rgba(255,193,7,.12);"
        return "background-color: rgba(26,115,232,.14); color:#d7e6ff;"
    st.dataframe(pred_df.style.map(_prob_color, subset=["ë‚´ì¼ìƒìŠ¹í™•ë¥ ","3ì¼í‰ê· í™•ë¥ "]),
                 use_container_width=True, hide_index=True)
    st.markdown("### ğŸ§  AI ì¸ì‚¬ì´íŠ¸")
    for _, row in pred_df.iterrows():
        if row["ë‚´ì¼ìƒìŠ¹í™•ë¥ "] == "-":
            st.markdown(f"- **{row['ì¢…ëª©ëª…']} ({row['í‹°ì»¤']})** â€” ë°ì´í„° ë¶€ì¡±/ì˜¤ë¥˜")
        else:
            arrow = "ğŸ”º" if row["ë‚´ì¼ìƒìŠ¹í™•ë¥ "]>=50 else "ğŸ”»"
            st.markdown(f"- **{row['ì¢…ëª©ëª…']} ({row['í‹°ì»¤']})** â€” ë‚´ì¼ ìƒìŠ¹ í™•ë¥  **{row['ë‚´ì¼ìƒìŠ¹í™•ë¥ ']}%** "
                        f"(3ì¼ í‰ê·  {row['3ì¼í‰ê· í™•ë¥ ']}%), ì‹ í˜¸ **{row['ì‹ í˜¸']}** {arrow}")

# =========================
# í…Œë§ˆ ê´€ë¦¬ì (ê°„ë‹¨í•œ ì¶”ê°€/ì €ì¥)
# =========================
st.markdown('<div id="sec-admin" class="section-h"></div>', unsafe_allow_html=True)
st.divider()
st.markdown("## ğŸ›  í…Œë§ˆ ê´€ë¦¬ì")

if "custom_themes" not in st.session_state:
    st.session_state.custom_themes = {}

with st.form("theme_form", clear_on_submit=False):
    st.markdown("### ìƒˆ í…Œë§ˆ/í‚¤ì›Œë“œ/ì¢…ëª© ì¶”ê°€")
    new_theme = st.text_input("í…Œë§ˆëª… (ì˜ˆ: ì „ë ¥)")
    kw_text   = st.text_input("í‚¤ì›Œë“œ ì½¤ë§ˆêµ¬ë¶„ (ì˜ˆ: ì „ë ¥, í•œì „, ì „ê¸°ìš”ê¸ˆ)")
    st.markdown("ì¢…ëª©ì€ â€˜ì´ë¦„|í‹°ì»¤â€™ í•œ ì¤„ì”© (ì˜ˆ: í•œêµ­ì „ë ¥|015760.KS)")
    stock_text = st.text_area("ëŒ€í‘œ ì¢…ëª© ëª©ë¡", height=100)
    save = st.form_submit_button("ğŸ’¾ ì €ì¥")
    if save and new_theme.strip():
        kws = [k.strip() for k in kw_text.split(",") if k.strip()]
        lines = [l.strip() for l in stock_text.splitlines() if "|" in l]
        pairs=[]
        for ln in lines:
            nm, tk = ln.split("|", 1)
            nm, tk = nm.strip(), tk.strip()
            if nm and tk:
                pairs.append((nm, tk))
        if kws:
            THEME_KEYWORDS[new_theme] = list(set(THEME_KEYWORDS.get(new_theme, []) + kws))
        if pairs:
            THEME_STOCKS[new_theme] = list({p[1]:p for p in (THEME_STOCKS.get(new_theme, []) + pairs)}.values())
        st.session_state.custom_themes[new_theme] = {"keywords":kws, "stocks":pairs}
        st.success(f"'{new_theme}' ì €ì¥ ì™„ë£Œ!")

if st.session_state.custom_themes:
    st.markdown("### í˜„ì¬ ì¶”ê°€ëœ í…Œë§ˆ")
    for t, v in st.session_state.custom_themes.items():
        st.write(f"- **{t}** / í‚¤ì›Œë“œ: {', '.join(v['keywords']) or '-'} / ì¢…ëª©: {', '.join([f'{n}({k})' for n,k in v['stocks']]) or '-'}")

st.caption("â€» ìºì‹œì— ì €ì¥ë©ë‹ˆë‹¤. ì½”ë“œ/ë ˆí¬ì— ì˜êµ¬ ì €ì¥í•˜ë ¤ë©´ ìˆ˜ë™ ë°˜ì˜í•´ì£¼ì„¸ìš”.")
