# -*- coding: utf-8 -*-
import math
from datetime import datetime, timedelta
from zoneinfo import ZoneInfo
from urllib.parse import quote_plus

import streamlit as st
import yfinance as yf
import feedparser
from bs4 import BeautifulSoup

KST = ZoneInfo("Asia/Seoul")

# ---------------------------------
# í˜ì´ì§€ ì„¤ì •
# ---------------------------------
st.set_page_config(
    page_title="AI ë‰´ìŠ¤ë¦¬í¬íŠ¸ â€“ ì‹¤ì‹œê°„ ì§€ìˆ˜ í‹°ì»¤ë°” + ìµœì‹  ë‰´ìŠ¤",
    layout="wide",
)

# ---------------------------------
# ê³µí†µ ìœ í‹¸
# ---------------------------------
def fmt_number(val: float, decimals: int = 2) -> str:
    try:
        if val is None or (isinstance(val, float) and (math.isnan(val) or math.isinf(val))):
            return "-"
        return f"{val:,.{decimals}f}"
    except Exception:
        return "-"

def fmt_percent(pct: float) -> str:
    try:
        if pct is None or (isinstance(pct, float) and (math.isnan(pct) or math.isinf(pct))):
            return "-"
        return f"{pct:+.2f}%"
    except Exception:
        return "-"

# ---------------------------------
# ì‹œì„¸ ìˆ˜ì§‘ (ì•ˆì •í˜•)
# ---------------------------------
def fetch_quote(ticker: str):
    """
    1) fast_info ì‹œë„
    2) ì‹¤íŒ¨ ì‹œ ìµœê·¼ 7ì¼/1ì¼ë´‰ ì¢…ê°€ë¡œ ê³„ì‚°
    """
    try:
        t = yf.Ticker(ticker)
        last = getattr(t.fast_info, "last_price", None)
        prev = getattr(t.fast_info, "previous_close", None)
        if last and prev:
            return float(last), float(prev)
    except Exception:
        pass

    try:
        df = yf.download(ticker, period="7d", interval="1d", auto_adjust=False, progress=False)
        closes = df.get("Close")
        if df is None or closes is None or closes.dropna().empty:
            return None, None
        closes = closes.dropna()
        last = float(closes.iloc[-1])
        prev = float(closes.iloc[-2]) if len(closes) >= 2 else None
        return last, prev
    except Exception:
        return None, None

def build_ticker_items():
    """
    í‹°ì»¤ë°”ì— í‘œì‹œí•  í•­ëª© êµ¬ì„±
    """
    rows = [
        ("KOSPI",   "^KS11", 2),
        ("KOSDAQ",  "^KQ11", 2),
        ("DOW",     "^DJI",  2),
        ("NASDAQ",  "^IXIC", 2),
        ("USD/KRW", "KRW=X", 2),
        ("WTI",     "CL=F",  2),
        ("Gold",    "GC=F",  2),
        ("Copper",  "HG=F",  3),
    ]
    items = []
    for (name, ticker, dp) in rows:
        last, prev = fetch_quote(ticker)
        delta = None
        pct = None
        if last is not None and prev not in (None, 0):
            delta = last - prev
            pct = (delta / prev) * 100.0
        items.append({
            "name": name,
            "last": fmt_number(last, dp),
            "pct": fmt_percent(pct) if pct is not None else "--",
            "is_up": (delta or 0) > 0,
            "is_down": (delta or 0) < 0,
        })
    return items

# ---------------------------------
# ë‰´ìŠ¤ ìˆ˜ì§‘ (Google News RSS) â€“ ì•ˆì • ë²„ì „
# ---------------------------------
def clean_html(raw_html: str) -> str:
    if not raw_html:
        return ""
    return BeautifulSoup(raw_html, "html.parser").get_text(" ", strip=True)

def _parse_entries(feed, days: int):
    now = datetime.now(KST)
    items = []
    for e in feed.entries:
        pub_dt = None
        if getattr(e, "published_parsed", None):
            pub_dt = datetime(*e.published_parsed[:6], tzinfo=KST)
        elif getattr(e, "updated_parsed", None):
            pub_dt = datetime(*e.updated_parsed[:6], tzinfo=KST)

        if pub_dt and (now - pub_dt) > timedelta(days=days):
            continue

        title = getattr(e, "title", "").strip()
        link = getattr(e, "link", "").strip()
        if link.startswith("./"):
            link = "https://news.google.com/" + link[2:]
        desc = clean_html(getattr(e, "summary", ""))

        items.append({
            "title": title,
            "link": link,
            "time": pub_dt.strftime("%Y-%m-%d %H:%M") if pub_dt else "-",
            "desc": desc
        })
    return items

def fetch_google_news_by_keyword(keyword: str, days: int = 3, max_items: int = 40):
    """
    ë‹¨ì¼ í‚¤ì›Œë“œë¥¼ ì•ˆì „í•˜ê²Œ RSS ì¡°íšŒ (User-Agent ì§€ì •)
    """
    q = quote_plus(keyword)
    url = f"https://news.google.com/rss/search?q={q}&hl=ko&gl=KR&ceid=KR%3Ako"
    feed = feedparser.parse(url, request_headers={"User-Agent": "Mozilla/5.0"})
    items = _parse_entries(feed, days)
    return items[:max_items]

# ì¹´í…Œê³ ë¦¬ â†’ ì—¬ëŸ¬ í‚¤ì›Œë“œ
CATEGORIES = {
    "ê²½ì œë‰´ìŠ¤": ["ê²½ì œ", "ë¬¼ê°€", "í™˜ìœ¨", "ë¬´ì—­", "ê¸ˆë¦¬", "ì„±ì¥ë¥ "],
    "ì£¼ì‹ë‰´ìŠ¤": ["ì½”ìŠ¤í”¼", "ì½”ìŠ¤ë‹¥", "ì¦ì‹œ", "ì£¼ê°€", "ì™¸êµ­ì¸ ë§¤ìˆ˜", "ê¸°ê´€ ë§¤ë§¤"],
    "ì‚°ì—…ë‰´ìŠ¤": ["ì‚°ì—…", "ë°˜ë„ì²´", "ë°°í„°ë¦¬", "ë¡œë´‡", "ì œì¡°", "ìˆ˜ì¶œì…"],
    "ì •ì±…ë‰´ìŠ¤": ["ì •ì±…", "ì •ë¶€", "ì˜ˆì‚°", "ì„¸ê¸ˆ", "ê·œì œ", "ì‚°ì—…ë¶€", "ê¸ˆìœµìœ„ì›íšŒ"],
}

def fetch_category_news(cat: str, days: int = 3, max_items: int = 100):
    """
    í‚¤ì›Œë“œë³„ë¡œ ì¡°íšŒí•´ì„œ í•©ì¹˜ê³ (ì¤‘ë³µ ì œê±°), ìµœì‹ ìˆœ ì •ë ¬
    """
    seen = set()
    merged = []
    for kw in CATEGORIES.get(cat, []):
        try:
            for it in fetch_google_news_by_keyword(kw, days=days, max_items=40):
                key = (it["title"], it["link"])
                if key in seen:
                    continue
                seen.add(key)
                merged.append(it)
        except Exception:
            continue

    def _key(x):
        try:
            return datetime.strptime(x["time"], "%Y-%m-%d %H:%M")
        except Exception:
            return datetime.min

    merged.sort(key=_key, reverse=True)
    return merged[:max_items]

# ---------------------------------
# UI â€“ í—¤ë” / í‹°ì»¤ë°”
# ---------------------------------
st.markdown("## ğŸ§  AI ë‰´ìŠ¤ë¦¬í¬íŠ¸ â€“ ì‹¤ì‹œê°„ ì§€ìˆ˜ í‹°ì»¤ë°”")
st.caption(f"ì—…ë°ì´íŠ¸: {datetime.now(KST).strftime('%Y-%m-%d %H:%M:%S (KST)')}")

colL, colR = st.columns([1, 5])
with colL:
    st.markdown("### ğŸ“Š ì˜¤ëŠ˜ì˜ ì‹œì¥ ìš”ì•½")
with colR:
    if st.button("ğŸ”„ ìƒˆë¡œê³ ì¹¨", use_container_width=False):
        st.cache_data.clear()
        st.rerun()

# í‹°ì»¤ ë°ì´í„°
ticker_items = build_ticker_items()

TICKER_CSS = """
<style>
.ticker-wrap {
  position: relative; overflow: hidden; width: 100%;
  border: 1px solid #263042; border-radius: 10px; background: #0f1420;
}
.ticker {
  display: inline-block; white-space: nowrap;
  padding: 8px 0; animation: scroll-left var(--speed, 35s) linear infinite;
}
@keyframes scroll-left {
  0% { transform: translateX(0); }
  100% { transform: translateX(-50%); }
}
.badge {
  display:inline-flex; align-items:center; gap:8px;
  background:#0f1420; border:1px solid #2b3a55; color:#c7d2fe;
  padding:6px 10px; margin:0 8px; border-radius:8px; font-weight:700;
}
.badge .name { color:#9fb3c8; font-weight:600; }
.badge .up   { color:#e66; }
.badge .down { color:#6aa2ff; }
.sep { color:#44526b; padding: 0 8px; }
</style>
"""
st.markdown(TICKER_CSS, unsafe_allow_html=True)

def render_ticker_line(items, speed_sec=35):
    badges = []
    for it in items:
        arrow = "â–²" if it["is_up"] else ("â–¼" if it["is_down"] else "â€¢")
        pct_class = "up" if it["is_up"] else ("down" if it["is_down"] else "")
        badges.append(
            f'<span class="badge"><span class="name">{it["name"]}</span>'
            f'{it["last"]} <span class="{pct_class}">{arrow} {it["pct"]}</span></span>'
        )
    line = '<span class="sep">|</span>'.join(badges)
    # ë‘ ë²ˆ ì´ì–´ë¶™ì—¬ ëŠê¹€ ì—†ì´
    html = f"""
    <div class="ticker-wrap" style="--speed:{speed_sec}s">
      <div class="ticker">{line} <span class="sep">|</span> {line}</div>
    </div>
    """
    st.markdown(html, unsafe_allow_html=True)

render_ticker_line(ticker_items, speed_sec=35)
st.caption("â€» ìƒìŠ¹=ë¹¨ê°•, í•˜ë½=íŒŒë‘ Â· ë°ì´í„° ì†ŒìŠ¤: Stooq â†’ Yahoo â†’ yfinance (10ë¶„ ì§€ì—°)")

st.divider()

# ---------------------------------
# UI â€“ ìµœì‹  ë‰´ìŠ¤ (ì¹´í…Œê³ ë¦¬/í˜ì´ì§€)
# ---------------------------------
st.markdown("## ğŸ“° ìµœì‹  ë‰´ìŠ¤ ìš”ì•½")

c1, c2 = st.columns([2, 1])
with c1:
    cat = st.selectbox("ğŸ“‚ ì¹´í…Œê³ ë¦¬ ì„ íƒ", list(CATEGORIES.keys()))
with c2:
    page = st.number_input("í˜ì´ì§€", min_value=1, value=1, step=1)

# ë°ì´í„° ë¡œë“œ
news_all = fetch_category_news(cat, days=3, max_items=100)
page_size = 10
total = len(news_all)
start = (page - 1) * page_size
end = start + page_size
news_page = news_all[start:end]

if not news_page:
    st.info("í‘œì‹œí•  ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤. (ìµœê·¼ 3ì¼ ë‚´ ê²°ê³¼ ì—†ìŒ)")
else:
    for i, n in enumerate(news_page, start=1 + start):
        title = n.get("title", "").strip() or "(ì œëª© ì—†ìŒ)"
        link = n.get("link", "")
        when = n.get("time", "-")
        desc = n.get("desc", "")

        st.markdown(
            f"**{i}. [{title}]({link})**  \n"
            f"<span style='color:#9aa0a6;font-size:0.9rem;'>{when}</span><br>"
            f"<span style='color:#aeb8c5;'>{desc}</span>",
            unsafe_allow_html=True
        )
        st.markdown("<hr style='border:0;border-top:1px solid #1f2937'/>", unsafe_allow_html=True)

st.caption(f"ğŸ—“ ìµœê·¼ 3ì¼ Â· ì¹´í…Œê³ ë¦¬: {cat} Â· {total}ê°œ ì¤‘ {start+1}-{min(end,total)} í‘œì‹œ")

with st.expander("ğŸ§ª ë””ë²„ê·¸(ìˆ˜ì§‘ê²°ê³¼ ë° ìš”ì²­ í™•ì¸)"):
    st.write({"cat": cat, "total": total, "page": page, "start": start, "end": end})
    # ================================
# ë‰´ìŠ¤ ê¸°ë°˜ í…Œë§ˆ ê°ì§€ + ëŒ€í‘œ ì¢…ëª© ì‹œì„¸ (ìƒ‰ìƒ/ì•„ì´ì½˜ ë²„ì „)
# ================================
st.divider()
st.markdown("## ğŸ”¥ ë‰´ìŠ¤ ê¸°ë°˜ í…Œë§ˆ ìš”ì•½")

THEME_KEYWORDS = {
    "AI":        ["ai", "ì¸ê³µì§€ëŠ¥", "ìƒì„±í˜•", "ì±—ë´‡", "ì˜¤í”ˆAI", "ì—”ë¹„ë””ì•„", "GPU"],
    "ë°˜ë„ì²´":     ["ë°˜ë„ì²´", "hbm", "ë©”ëª¨ë¦¬", "íŒŒìš´ë“œë¦¬", "ì¹©", "ë¨", "ì†Œë¶€ì¥"],
    "ë¡œë´‡":       ["ë¡œë´‡", "ììœ¨ì£¼í–‰ë¡œë´‡", "AMR", "í˜‘ë™ë¡œë´‡", "ë¡œë³´í‹±ìŠ¤"],
    "ì´ì°¨ì „ì§€":    ["2ì°¨ì „ì§€", "ì´ì°¨ì „ì§€", "ë°°í„°ë¦¬", "ì „ê³ ì²´", "ì–‘ê·¹ì¬", "ìŒê·¹ì¬", "LFP"],
    "ì—ë„ˆì§€":     ["ì—ë„ˆì§€", "ìœ ê°€", "ì „ë ¥", "ê°€ìŠ¤", "ì •ìœ ", "ì¬ìƒì—ë„ˆì§€", "í’ë ¥", "íƒœì–‘ê´‘"],
    "ì¡°ì„ ":       ["ì¡°ì„ ", "ì„ ë°•", "ìˆ˜ì£¼", "LNGì„ ", "í•´ìš´"],
    "LNG":       ["lng", "ì•¡í™”ì²œì—°ê°€ìŠ¤", "ê°€ìŠ¤ê³µì‚¬", "í„°ë¯¸ë„"],
    "ì›ì „":       ["ì›ì „", "ì›ìë ¥", "SMR", "ì›ì „ìˆ˜ì¶œ", "ì›ì „ì •ë¹„"],
    "ë°”ì´ì˜¤":     ["ë°”ì´ì˜¤", "ì œì•½", "ì‹ ì•½", "ì„ìƒ", "í•­ì•”", "ë°”ì´ì˜¤ì‹œë°€ëŸ¬"],
}

THEME_STOCKS = {
    "AI":       [("ì‚¼ì„±ì „ì","005930.KS"), ("ë„¤ì´ë²„","035420.KS"), ("ì¹´ì¹´ì˜¤","035720.KS"), ("ë”ì¡´ë¹„ì¦ˆì˜¨","012510.KS")],
    "ë°˜ë„ì²´":   [("ì‚¼ì„±ì „ì","005930.KS"), ("SKí•˜ì´ë‹‰ìŠ¤","000660.KS"), ("DBí•˜ì´í…","000990.KS"), ("í•œë¯¸ë°˜ë„ì²´","042700.KQ")],
    "ë¡œë´‡":     [("ë ˆì¸ë³´ìš°ë¡œë³´í‹±ìŠ¤","277810.KQ"), ("ìœ ì§„ë¡œë´‡","056080.KQ"), ("í‹°ë¡œë³´í‹±ìŠ¤","117730.KQ"), ("ë¡œë³´ìŠ¤íƒ€","090360.KQ")],
    "ì´ì°¨ì „ì§€": [("LGì—ë„ˆì§€ì†”ë£¨ì…˜","373220.KS"), ("í¬ìŠ¤ì½”í“¨ì²˜ì— ","003670.KS"), ("ì—ì½”í”„ë¡œ","086520.KQ"), ("ì—ì½”í”„ë¡œë¹„ì— ","247540.KQ")],
    "ì—ë„ˆì§€":   [("í•œêµ­ì „ë ¥","015760.KS"), ("ë‘ì‚°ì—ë„ˆë¹Œë¦¬í‹°","034020.KS"), ("GS","078930.KS"), ("SKì´ë…¸ë² ì´ì…˜","096770.KS")],
    "ì¡°ì„ ":     [("HDí•œêµ­ì¡°ì„ í•´ì–‘","009540.KS"), ("HDí˜„ëŒ€ë¯¸í¬","010620.KS"), ("ì‚¼ì„±ì¤‘ê³µì—…","010140.KS"), ("í•œí™”ì˜¤ì…˜","042660.KS")],
    "LNG":     [("í•œêµ­ê°€ìŠ¤ê³µì‚¬","036460.KS"), ("ì§€ì—ìŠ¤ì´","053050.KQ"), ("ëŒ€ì„±ì—ë„ˆì§€","117580.KQ"), ("SKê°€ìŠ¤","018670.KS")],
    "ì›ì „":     [("ë‘ì‚°ì—ë„ˆë¹Œë¦¬í‹°","034020.KS"), ("ìš°ì§„","105840.KQ"), ("í•œì „KPS","051600.KS"), ("í•œì „ê¸°ìˆ ","052690.KS")],
    "ë°”ì´ì˜¤":   [("ì‚¼ì„±ë°”ì´ì˜¤ë¡œì§ìŠ¤","207940.KS"), ("ì…€íŠ¸ë¦¬ì˜¨","068270.KS"), ("ì—ìŠ¤í‹°íŒœ","237690.KQ"), ("ë©”ë””í†¡ìŠ¤","086900.KQ")],
}

def normalize_text(s: str) -> str:
    return (s or "").lower()

def detect_themes(news_list):
    counts = {t: 0 for t in THEME_KEYWORDS}
    sample_link = {t: "" for t in THEME_KEYWORDS}

    for n in news_list:
        text = normalize_text(f"{n.get('title','')} {n.get('desc','')}")
        for theme, kws in THEME_KEYWORDS.items():
            if any(k in text for k in kws):
                counts[theme] += 1
                if not sample_link[theme]:
                    sample_link[theme] = n.get("link","")

    rows = []
    for theme, c in counts.items():
        if c > 0:
            rows.append({
                "theme": theme,
                "count": c,
                "sample_link": sample_link[theme],
                "rep_stocks": " Â· ".join([nm for nm, _ in THEME_STOCKS.get(theme, [])]) or "-",
            })
    rows.sort(key=lambda x: x["count"], reverse=True)
    return rows


all_news_3days = []
for cat_name in CATEGORIES.keys():
    all_news_3days.extend(fetch_category_news(cat_name, days=3, max_items=100))

theme_rows = detect_themes(all_news_3days)

if not theme_rows:
    st.info("ìµœê·¼ 3ì¼ ê¸°ì¤€ í…Œë§ˆ ì‹ í˜¸ê°€ ì•½í•©ë‹ˆë‹¤. (ë§¤ì¹­ ê²°ê³¼ ì—†ìŒ)")
else:
    top5 = theme_rows[:5]
    badge_html = "<style>.tbadge{display:inline-block;margin:6px 6px 0 0;padding:6px 10px;border:1px solid #2b3a55;border-radius:10px;background:#0f1420} .tbadge b{color:#c7d2fe}</style>"
    st.markdown(badge_html, unsafe_allow_html=True)
    st.markdown("**TOP í…Œë§ˆ**: " + " ".join([f"<span class='tbadge'><b>{r['theme']}</b> {r['count']}ê±´</span>" for r in top5]), unsafe_allow_html=True)

    import pandas as pd
    st.dataframe(pd.DataFrame(theme_rows), use_container_width=True, hide_index=True)

    st.markdown("### ğŸ§© ëŒ€í‘œ ì¢…ëª© ì‹œì„¸ (ìƒìŠ¹=ë¹¨ê°• / í•˜ë½=íŒŒë‘)")

    def safe_yf_price(ticker):
        try:
            last, prev = fetch_quote(ticker)
            if last is None or prev in (None, 0):
                return None, None, "gray"
            delta = (last - prev) / prev * 100
            color = "red" if delta > 0 else ("blue" if delta < 0 else "gray")
            return fmt_number(last, 0), fmt_percent(delta), color
        except Exception:
            return None, None, "gray"

    for tr in top5:
        theme = tr["theme"]
        stocks = THEME_STOCKS.get(theme, [])
        if not stocks:
            continue
        st.write(f"**{theme}**")
        cols = st.columns(len(stocks))
        for col, (name, ticker) in zip(cols, stocks):
            with col:
                px, chg, color = safe_yf_price(ticker)
                if px:
                    arrow = "â–²" if color == "red" else ("â–¼" if color == "blue" else "â– ")
                    st.markdown(f"<b>{name}</b><br><span style='color:{color}'>{px} {arrow} {chg}</span><br><small>{ticker}</small>", unsafe_allow_html=True)
                else:
                    st.markdown(f"**{name}**<br>-<br><small>{ticker}</small>", unsafe_allow_html=True)
        st.divider()
