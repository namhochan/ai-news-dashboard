# -*- coding: utf-8 -*-
import math
import numpy as np
from datetime import datetime, timedelta
from zoneinfo import ZoneInfo
from urllib.parse import quote_plus

import streamlit as st
import yfinance as yf
import feedparser
from bs4 import BeautifulSoup

KST = ZoneInfo("Asia/Seoul")

# ---------------------------------
# í˜ì´ì§€ ì„¤ì •
# ---------------------------------
st.set_page_config(
    page_title="AI ë‰´ìŠ¤ë¦¬í¬íŠ¸ â€“ ì‹¤ì‹œê°„ ì§€ìˆ˜ í‹°ì»¤ë°” + ìµœì‹  ë‰´ìŠ¤",
    layout="wide",
)

# ---------------------------------
# ê³µí†µ ìœ í‹¸
# ---------------------------------
def fmt_number(val: float, decimals: int = 2) -> str:
    try:
        if val is None or (isinstance(val, float) and (math.isnan(val) or math.isinf(val))):
            return "-"
        return f"{val:,.{decimals}f}"
    except Exception:
        return "-"

def fmt_percent(pct: float) -> str:
    try:
        if pct is None or (isinstance(pct, float) and (math.isnan(pct) or math.isinf(pct))):
            return "-"
        return f"{pct:+.2f}%"
    except Exception:
        return "-"

# ---------------------------------
# ì‹œì„¸ ìˆ˜ì§‘ (ì•ˆì •í˜•)
# ---------------------------------
def fetch_quote(ticker: str):
    """
    1) fast_info ì‹œë„
    2) ì‹¤íŒ¨ ì‹œ ìµœê·¼ 7ì¼/1ì¼ë´‰ ì¢…ê°€ë¡œ ê³„ì‚°
    """
    try:
        t = yf.Ticker(ticker)
        last = getattr(t.fast_info, "last_price", None)
        prev = getattr(t.fast_info, "previous_close", None)
        if last and prev:
            return float(last), float(prev)
    except Exception:
        pass

    try:
        df = yf.download(ticker, period="7d", interval="1d", auto_adjust=False, progress=False)
        closes = df.get("Close")
        if df is None or closes is None or closes.dropna().empty:
            return None, None
        closes = closes.dropna()
        last = float(closes.iloc[-1])
        prev = float(closes.iloc[-2]) if len(closes) >= 2 else None
        return last, prev
    except Exception:
        return None, None

def build_ticker_items():
    """
    í‹°ì»¤ë°”ì— í‘œì‹œí•  í•­ëª© êµ¬ì„±
    """
    rows = [
        ("KOSPI",   "^KS11", 2),
        ("KOSDAQ",  "^KQ11", 2),
        ("DOW",     "^DJI",  2),
        ("NASDAQ",  "^IXIC", 2),
        ("USD/KRW", "KRW=X", 2),
        ("WTI",     "CL=F",  2),
        ("Gold",    "GC=F",  2),
        ("Copper",  "HG=F",  3),
    ]
    items = []
    for (name, ticker, dp) in rows:
        last, prev = fetch_quote(ticker)
        delta = None
        pct = None
        if last is not None and prev not in (None, 0):
            delta = last - prev
            pct = (delta / prev) * 100.0
        items.append({
            "name": name,
            "last": fmt_number(last, dp),
            "pct": fmt_percent(pct) if pct is not None else "--",
            "is_up": (delta or 0) > 0,
            "is_down": (delta or 0) < 0,
        })
    return items

# ---------------------------------
# ë‰´ìŠ¤ ìˆ˜ì§‘ (Google News RSS) â€“ ì•ˆì • ë²„ì „
# ---------------------------------
def clean_html(raw_html: str) -> str:
    if not raw_html:
        return ""
    return BeautifulSoup(raw_html, "html.parser").get_text(" ", strip=True)

def _parse_entries(feed, days: int):
    now = datetime.now(KST)
    items = []
    for e in feed.entries:
        pub_dt = None
        if getattr(e, "published_parsed", None):
            pub_dt = datetime(*e.published_parsed[:6], tzinfo=KST)
        elif getattr(e, "updated_parsed", None):
            pub_dt = datetime(*e.updated_parsed[:6], tzinfo=KST)

        if pub_dt and (now - pub_dt) > timedelta(days=days):
            continue

        title = getattr(e, "title", "").strip()
        link = getattr(e, "link", "").strip()
        if link.startswith("./"):
            link = "https://news.google.com/" + link[2:]
        desc = clean_html(getattr(e, "summary", ""))

        items.append({
            "title": title,
            "link": link,
            "time": pub_dt.strftime("%Y-%m-%d %H:%M") if pub_dt else "-",
            "desc": desc
        })
    return items

def fetch_google_news_by_keyword(keyword: str, days: int = 3, max_items: int = 40):
    """
    ë‹¨ì¼ í‚¤ì›Œë“œë¥¼ ì•ˆì „í•˜ê²Œ RSS ì¡°íšŒ (User-Agent ì§€ì •)
    """
    q = quote_plus(keyword)
    url = f"https://news.google.com/rss/search?q={q}&hl=ko&gl=KR&ceid=KR%3Ako"
    feed = feedparser.parse(url, request_headers={"User-Agent": "Mozilla/5.0"})
    items = _parse_entries(feed, days)
    return items[:max_items]

# ì¹´í…Œê³ ë¦¬ â†’ ì—¬ëŸ¬ í‚¤ì›Œë“œ
CATEGORIES = {
    "ê²½ì œë‰´ìŠ¤": ["ê²½ì œ", "ë¬¼ê°€", "í™˜ìœ¨", "ë¬´ì—­", "ê¸ˆë¦¬", "ì„±ì¥ë¥ "],
    "ì£¼ì‹ë‰´ìŠ¤": ["ì½”ìŠ¤í”¼", "ì½”ìŠ¤ë‹¥", "ì¦ì‹œ", "ì£¼ê°€", "ì™¸êµ­ì¸ ë§¤ìˆ˜", "ê¸°ê´€ ë§¤ë§¤"],
    "ì‚°ì—…ë‰´ìŠ¤": ["ì‚°ì—…", "ë°˜ë„ì²´", "ë°°í„°ë¦¬", "ë¡œë´‡", "ì œì¡°", "ìˆ˜ì¶œì…"],
    "ì •ì±…ë‰´ìŠ¤": ["ì •ì±…", "ì •ë¶€", "ì˜ˆì‚°", "ì„¸ê¸ˆ", "ê·œì œ", "ì‚°ì—…ë¶€", "ê¸ˆìœµìœ„ì›íšŒ"],
}

def fetch_category_news(cat: str, days: int = 3, max_items: int = 100):
    """
    í‚¤ì›Œë“œë³„ë¡œ ì¡°íšŒí•´ì„œ í•©ì¹˜ê³ (ì¤‘ë³µ ì œê±°), ìµœì‹ ìˆœ ì •ë ¬
    """
    seen = set()
    merged = []
    for kw in CATEGORIES.get(cat, []):
        try:
            for it in fetch_google_news_by_keyword(kw, days=days, max_items=40):
                key = (it["title"], it["link"])
                if key in seen:
                    continue
                seen.add(key)
                merged.append(it)
        except Exception:
            continue

    def _key(x):
        try:
            return datetime.strptime(x["time"], "%Y-%m-%d %H:%M")
        except Exception:
            return datetime.min

    merged.sort(key=_key, reverse=True)
    return merged[:max_items]

# ---------------------------------
# UI â€“ í—¤ë” / í‹°ì»¤ë°”
# ---------------------------------
st.markdown("## ğŸ§  AI ë‰´ìŠ¤ë¦¬í¬íŠ¸ â€“ ì‹¤ì‹œê°„ ì§€ìˆ˜ í‹°ì»¤ë°”")
st.caption(f"ì—…ë°ì´íŠ¸: {datetime.now(KST).strftime('%Y-%m-%d %H:%M:%S (KST)')}")

colL, colR = st.columns([1, 5])
with colL:
    st.markdown("### ğŸ“Š ì˜¤ëŠ˜ì˜ ì‹œì¥ ìš”ì•½")
with colR:
    if st.button("ğŸ”„ ìƒˆë¡œê³ ì¹¨", use_container_width=False):
        st.cache_data.clear()
        st.rerun()

# í‹°ì»¤ ë°ì´í„°
ticker_items = build_ticker_items()

TICKER_CSS = """
<style>
.ticker-wrap {
  position: relative; overflow: hidden; width: 100%;
  border: 1px solid #263042; border-radius: 10px; background: #0f1420;
}
.ticker {
  display: inline-block; white-space: nowrap;
  padding: 8px 0; animation: scroll-left var(--speed, 35s) linear infinite;
}
@keyframes scroll-left {
  0% { transform: translateX(0); }
  100% { transform: translateX(-50%); }
}
.badge {
  display:inline-flex; align-items:center; gap:8px;
  background:#0f1420; border:1px solid #2b3a55; color:#c7d2fe;
  padding:6px 10px; margin:0 8px; border-radius:8px; font-weight:700;
}
.badge .name { color:#9fb3c8; font-weight:600; }
.badge .up   { color:#e66; }
.badge .down { color:#6aa2ff; }
.sep { color:#44526b; padding: 0 8px; }
</style>
"""
st.markdown(TICKER_CSS, unsafe_allow_html=True)

def render_ticker_line(items, speed_sec=35):
    badges = []
    for it in items:
        arrow = "â–²" if it["is_up"] else ("â–¼" if it["is_down"] else "â€¢")
        pct_class = "up" if it["is_up"] else ("down" if it["is_down"] else "")
        badges.append(
            f'<span class="badge"><span class="name">{it["name"]}</span>'
            f'{it["last"]} <span class="{pct_class}">{arrow} {it["pct"]}</span></span>'
        )
    line = '<span class="sep">|</span>'.join(badges)
    # ë‘ ë²ˆ ì´ì–´ë¶™ì—¬ ëŠê¹€ ì—†ì´
    html = f"""
    <div class="ticker-wrap" style="--speed:{speed_sec}s">
      <div class="ticker">{line} <span class="sep">|</span> {line}</div>
    </div>
    """
    st.markdown(html, unsafe_allow_html=True)

render_ticker_line(ticker_items, speed_sec=35)
st.caption("â€» ìƒìŠ¹=ë¹¨ê°•, í•˜ë½=íŒŒë‘ Â· ë°ì´í„° ì†ŒìŠ¤: Stooq â†’ Yahoo â†’ yfinance (10ë¶„ ì§€ì—°)")

st.divider()

# ---------------------------------
# UI â€“ ìµœì‹  ë‰´ìŠ¤ (ì¹´í…Œê³ ë¦¬/í˜ì´ì§€)
# ---------------------------------
st.markdown("## ğŸ“° ìµœì‹  ë‰´ìŠ¤ ìš”ì•½")

c1, c2 = st.columns([2, 1])
with c1:
    cat = st.selectbox("ğŸ“‚ ì¹´í…Œê³ ë¦¬ ì„ íƒ", list(CATEGORIES.keys()))
with c2:
    page = st.number_input("í˜ì´ì§€", min_value=1, value=1, step=1)

# ë°ì´í„° ë¡œë“œ
news_all = fetch_category_news(cat, days=3, max_items=100)
page_size = 10
total = len(news_all)
start = (page - 1) * page_size
end = start + page_size
news_page = news_all[start:end]

if not news_page:
    st.info("í‘œì‹œí•  ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤. (ìµœê·¼ 3ì¼ ë‚´ ê²°ê³¼ ì—†ìŒ)")
else:
    for i, n in enumerate(news_page, start=1 + start):
        title = n.get("title", "").strip() or "(ì œëª© ì—†ìŒ)"
        link = n.get("link", "")
        when = n.get("time", "-")
        desc = n.get("desc", "")

        st.markdown(
            f"**{i}. [{title}]({link})**  \n"
            f"<span style='color:#9aa0a6;font-size:0.9rem;'>{when}</span><br>"
            f"<span style='color:#aeb8c5;'>{desc}</span>",
            unsafe_allow_html=True
        )
        st.markdown("<hr style='border:0;border-top:1px solid #1f2937'/>", unsafe_allow_html=True)

st.caption(f"ğŸ—“ ìµœê·¼ 3ì¼ Â· ì¹´í…Œê³ ë¦¬: {cat} Â· {total}ê°œ ì¤‘ {start+1}-{min(end,total)} í‘œì‹œ")

with st.expander("ğŸ§ª ë””ë²„ê·¸(ìˆ˜ì§‘ê²°ê³¼ ë° ìš”ì²­ í™•ì¸)"):
    st.write({"cat": cat, "total": total, "page": page, "start": start, "end": end})
    # ================================
# ë‰´ìŠ¤ ê¸°ë°˜ í…Œë§ˆ ê°ì§€ + ëŒ€í‘œ ì¢…ëª© ì‹œì„¸ (ìƒ‰ìƒ/ì•„ì´ì½˜ ë²„ì „)
# ================================
st.divider()
st.markdown("## ğŸ”¥ ë‰´ìŠ¤ ê¸°ë°˜ í…Œë§ˆ ìš”ì•½")

THEME_KEYWORDS = {
    "AI":        ["ai", "ì¸ê³µì§€ëŠ¥", "ìƒì„±í˜•", "ì±—ë´‡", "ì˜¤í”ˆAI", "ì—”ë¹„ë””ì•„", "GPU"],
    "ë°˜ë„ì²´":     ["ë°˜ë„ì²´", "hbm", "ë©”ëª¨ë¦¬", "íŒŒìš´ë“œë¦¬", "ì¹©", "ë¨", "ì†Œë¶€ì¥"],
    "ë¡œë´‡":       ["ë¡œë´‡", "ììœ¨ì£¼í–‰ë¡œë´‡", "AMR", "í˜‘ë™ë¡œë´‡", "ë¡œë³´í‹±ìŠ¤"],
    "ì´ì°¨ì „ì§€":    ["2ì°¨ì „ì§€", "ì´ì°¨ì „ì§€", "ë°°í„°ë¦¬", "ì „ê³ ì²´", "ì–‘ê·¹ì¬", "ìŒê·¹ì¬", "LFP"],
    "ì—ë„ˆì§€":     ["ì—ë„ˆì§€", "ìœ ê°€", "ì „ë ¥", "ê°€ìŠ¤", "ì •ìœ ", "ì¬ìƒì—ë„ˆì§€", "í’ë ¥", "íƒœì–‘ê´‘"],
    "ì¡°ì„ ":       ["ì¡°ì„ ", "ì„ ë°•", "ìˆ˜ì£¼", "LNGì„ ", "í•´ìš´"],
    "LNG":       ["lng", "ì•¡í™”ì²œì—°ê°€ìŠ¤", "ê°€ìŠ¤ê³µì‚¬", "í„°ë¯¸ë„"],
    "ì›ì „":       ["ì›ì „", "ì›ìë ¥", "SMR", "ì›ì „ìˆ˜ì¶œ", "ì›ì „ì •ë¹„"],
    "ë°”ì´ì˜¤":     ["ë°”ì´ì˜¤", "ì œì•½", "ì‹ ì•½", "ì„ìƒ", "í•­ì•”", "ë°”ì´ì˜¤ì‹œë°€ëŸ¬"],
}

THEME_STOCKS = {
    "AI":       [("ì‚¼ì„±ì „ì","005930.KS"), ("ë„¤ì´ë²„","035420.KS"), ("ì¹´ì¹´ì˜¤","035720.KS"), ("ë”ì¡´ë¹„ì¦ˆì˜¨","012510.KS")],
    "ë°˜ë„ì²´":   [("ì‚¼ì„±ì „ì","005930.KS"), ("SKí•˜ì´ë‹‰ìŠ¤","000660.KS"), ("DBí•˜ì´í…","000990.KS"), ("í•œë¯¸ë°˜ë„ì²´","042700.KQ")],
    "ë¡œë´‡":     [("ë ˆì¸ë³´ìš°ë¡œë³´í‹±ìŠ¤","277810.KQ"), ("ìœ ì§„ë¡œë´‡","056080.KQ"), ("í‹°ë¡œë³´í‹±ìŠ¤","117730.KQ"), ("ë¡œë³´ìŠ¤íƒ€","090360.KQ")],
    "ì´ì°¨ì „ì§€": [("LGì—ë„ˆì§€ì†”ë£¨ì…˜","373220.KS"), ("í¬ìŠ¤ì½”í“¨ì²˜ì— ","003670.KS"), ("ì—ì½”í”„ë¡œ","086520.KQ"), ("ì—ì½”í”„ë¡œë¹„ì— ","247540.KQ")],
    "ì—ë„ˆì§€":   [("í•œêµ­ì „ë ¥","015760.KS"), ("ë‘ì‚°ì—ë„ˆë¹Œë¦¬í‹°","034020.KS"), ("GS","078930.KS"), ("SKì´ë…¸ë² ì´ì…˜","096770.KS")],
    "ì¡°ì„ ":     [("HDí•œêµ­ì¡°ì„ í•´ì–‘","009540.KS"), ("HDí˜„ëŒ€ë¯¸í¬","010620.KS"), ("ì‚¼ì„±ì¤‘ê³µì—…","010140.KS"), ("í•œí™”ì˜¤ì…˜","042660.KS")],
    "LNG":     [("í•œêµ­ê°€ìŠ¤ê³µì‚¬","036460.KS"), ("ì§€ì—ìŠ¤ì´","053050.KQ"), ("ëŒ€ì„±ì—ë„ˆì§€","117580.KQ"), ("SKê°€ìŠ¤","018670.KS")],
    "ì›ì „":     [("ë‘ì‚°ì—ë„ˆë¹Œë¦¬í‹°","034020.KS"), ("ìš°ì§„","105840.KQ"), ("í•œì „KPS","051600.KS"), ("í•œì „ê¸°ìˆ ","052690.KS")],
    "ë°”ì´ì˜¤":   [("ì‚¼ì„±ë°”ì´ì˜¤ë¡œì§ìŠ¤","207940.KS"), ("ì…€íŠ¸ë¦¬ì˜¨","068270.KS"), ("ì—ìŠ¤í‹°íŒœ","237690.KQ"), ("ë©”ë””í†¡ìŠ¤","086900.KQ")],
}

def normalize_text(s: str) -> str:
    return (s or "").lower()

def detect_themes(news_list):
    counts = {t: 0 for t in THEME_KEYWORDS}
    sample_link = {t: "" for t in THEME_KEYWORDS}

    for n in news_list:
        text = normalize_text(f"{n.get('title','')} {n.get('desc','')}")
        for theme, kws in THEME_KEYWORDS.items():
            if any(k in text for k in kws):
                counts[theme] += 1
                if not sample_link[theme]:
                    sample_link[theme] = n.get("link","")

    rows = []
    for theme, c in counts.items():
        if c > 0:
            rows.append({
                "theme": theme,
                "count": c,
                "sample_link": sample_link[theme],
                "rep_stocks": " Â· ".join([nm for nm, _ in THEME_STOCKS.get(theme, [])]) or "-",
            })
    rows.sort(key=lambda x: x["count"], reverse=True)
    return rows


all_news_3days = []
for cat_name in CATEGORIES.keys():
    all_news_3days.extend(fetch_category_news(cat_name, days=3, max_items=100))

theme_rows = detect_themes(all_news_3days)

if not theme_rows:
    st.info("ìµœê·¼ 3ì¼ ê¸°ì¤€ í…Œë§ˆ ì‹ í˜¸ê°€ ì•½í•©ë‹ˆë‹¤. (ë§¤ì¹­ ê²°ê³¼ ì—†ìŒ)")
else:
    top5 = theme_rows[:5]
    badge_html = "<style>.tbadge{display:inline-block;margin:6px 6px 0 0;padding:6px 10px;border:1px solid #2b3a55;border-radius:10px;background:#0f1420} .tbadge b{color:#c7d2fe}</style>"
    st.markdown(badge_html, unsafe_allow_html=True)
    st.markdown("**TOP í…Œë§ˆ**: " + " ".join([f"<span class='tbadge'><b>{r['theme']}</b> {r['count']}ê±´</span>" for r in top5]), unsafe_allow_html=True)

    import pandas as pd
    st.dataframe(pd.DataFrame(theme_rows), use_container_width=True, hide_index=True)

    st.markdown("### ğŸ§© ëŒ€í‘œ ì¢…ëª© ì‹œì„¸ (ìƒìŠ¹=ë¹¨ê°• / í•˜ë½=íŒŒë‘)")

    def safe_yf_price(ticker):
        try:
            last, prev = fetch_quote(ticker)
            if last is None or prev in (None, 0):
                return None, None, "gray"
            delta = (last - prev) / prev * 100
            color = "red" if delta > 0 else ("blue" if delta < 0 else "gray")
            return fmt_number(last, 0), fmt_percent(delta), color
        except Exception:
            return None, None, "gray"

    for tr in top5:
        theme = tr["theme"]
        stocks = THEME_STOCKS.get(theme, [])
        if not stocks:
            continue
        st.write(f"**{theme}**")
        cols = st.columns(len(stocks))
        for col, (name, ticker) in zip(cols, stocks):
            with col:
                px, chg, color = safe_yf_price(ticker)
                if px:
                    arrow = "â–²" if color == "red" else ("â–¼" if color == "blue" else "â– ")
                    st.markdown(f"<b>{name}</b><br><span style='color:{color}'>{px} {arrow} {chg}</span><br><small>{ticker}</small>", unsafe_allow_html=True)
                else:
                    st.markdown(f"**{name}**<br>-<br><small>{ticker}</small>", unsafe_allow_html=True)
        st.divider()
# =====================================
# ğŸ§  1ë‹¨ê³„: AI ë‰´ìŠ¤ ìš”ì•½ì—”ì§„ (ë”ë³´ê¸° ë²„íŠ¼í˜•)
# =====================================
import re
from collections import Counter

st.divider()
st.markdown("## ğŸ§  AI ë‰´ìŠ¤ ìš”ì•½ì—”ì§„")

def extract_keywords(texts, topn=10):
    """ê°€ì¥ ë§ì´ ë“±ì¥í•˜ëŠ” ë‹¨ì–´ ê¸°ë°˜ í‚¤ì›Œë“œ ì¶”ì¶œ"""
    words = []
    for t in texts:
        t = re.sub(r"[^ê°€-í£A-Za-z0-9\s]", " ", t)
        words.extend([w for w in t.split() if len(w) >= 2])
    counter = Counter(words)
    return [w for w, _ in counter.most_common(topn)]

def summarize_news(news_list, n_sent=5):
    """ë‰´ìŠ¤ ë‚´ìš© ì¤‘ í•µì‹¬ ë¬¸ì¥ ìƒìœ„ nê°œ ì¶”ì¶œ"""
    texts = [n.get("title","") + " " + n.get("desc","") for n in news_list]
    if not texts:
        return []
    full_text = " ".join(texts)
    sentences = re.split(r'[.!?]\s+', full_text)
    sentences = [s for s in sentences if len(s.strip()) > 20]
    scores = {s: sum(word in full_text for word in s.split()) for s in sentences}
    ranked = sorted(scores.items(), key=lambda x: x[1], reverse=True)
    return [s for s, _ in ranked[:n_sent]]

# ë‰´ìŠ¤ ë°ì´í„° ê¸°ë°˜ í‚¤ì›Œë“œ + ìš”ì•½ ìƒì„±
titles = [n["title"] for cat in CATEGORIES for n in fetch_category_news(cat, 3, 100)]
keywords = extract_keywords(titles, topn=10)
summary = summarize_news(all_news_3days, n_sent=5)

# í•µì‹¬ í‚¤ì›Œë“œ ì¶œë ¥
st.markdown("### ğŸ“Œ í•µì‹¬ í‚¤ì›Œë“œ TOP10")
if keywords:
    st.write(", ".join(keywords))
else:
    st.info("í‚¤ì›Œë“œ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")

# ë”ë³´ê¸° ë²„íŠ¼í˜• ìš”ì•½ë¬¸
st.markdown("### ğŸ“° í•µì‹¬ ìš”ì•½ë¬¸")
if summary:
    st.markdown(f"**ìš”ì•½:** {summary[0][:150]}...")  # ì²« ì¤„ë§Œ ë¯¸ë¦¬ ë³´ì—¬ì¤Œ
    with st.expander("ì „ì²´ ìš”ì•½ë¬¸ ë³´ê¸° ğŸ‘‡"):
        for s in summary:
            st.markdown(f"- {s.strip()}")
else:
    st.info("ìš”ì•½ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

# =====================================
# ğŸ“Š 2ë‹¨ê³„: í…Œë§ˆë³„ ìƒìŠ¹ í™•ë¥  ì˜ˆì¸¡ (AI ë¦¬ìŠ¤í¬ë ˆë²¨ + í…Œë§ˆê°•ë„)
# =====================================
st.divider()
st.markdown("## ğŸ“Š AI ìƒìŠ¹ í™•ë¥  ì˜ˆì¸¡ ë¦¬í¬íŠ¸")

def calc_theme_strength(count, avg_delta):
    """í…Œë§ˆê°•ë„: ë‰´ìŠ¤ë¹ˆë„(0~1) + í‰ê· ë“±ë½(0~1)"""
    freq_score = min(count / 20, 1.0)
    price_score = min(max((avg_delta + 5) / 10, 0), 1.0)
    total = (freq_score * 0.6 + price_score * 0.4) * 5
    return round(total, 1)

def calc_risk_level(avg_delta):
    """AI ë¦¬ìŠ¤í¬ ë ˆë²¨ (1~5, í•˜ë½í­ í´ìˆ˜ë¡ ë†’ìŒ)"""
    if avg_delta >= 3: return 1
    if avg_delta >= 1: return 2
    if avg_delta >= -1: return 3
    if avg_delta >= -3: return 4
    return 5

report_rows = []
for tr in theme_rows[:5]:
    theme = tr["theme"]
    stocks = THEME_STOCKS.get(theme, [])
    deltas = []
    for _, ticker in stocks:
        try:
            last, prev = fetch_quote(ticker)
            if last and prev:
                deltas.append((last - prev) / prev * 100)
        except Exception:
            pass
    avg_delta = np.mean(deltas) if deltas else 0
    theme_strength = calc_theme_strength(tr["count"], avg_delta)
    risk_level = calc_risk_level(avg_delta)
    report_rows.append({
        "í…Œë§ˆ": theme,
        "ë‰´ìŠ¤ë¹ˆë„": tr["count"],
        "í‰ê· ë“±ë½(%)": round(avg_delta, 2),
        "í…Œë§ˆê°•ë„(1~5)": theme_strength,
        "ë¦¬ìŠ¤í¬ë ˆë²¨(1~5)": risk_level,
    })

st.dataframe(report_rows, use_container_width=True, hide_index=True)
st.caption("â€» í…Œë§ˆê°•ë„â†‘ = ë‰´ìŠ¤ + ê°€ê²©ì´ ëª¨ë‘ í™œë°œí•œ ìƒíƒœ / ë¦¬ìŠ¤í¬ë ˆë²¨â†‘ = ë³€ë™ì„±Â·í•˜ë½ ê°€ëŠ¥ì„± ë†’ìŒ")
# =====================================
# ğŸš€ 3ë‹¨ê³„: AI ìœ ë§ ì¢…ëª© ìë™ ì¶”ì²œ (Top5)
# =====================================
st.divider()
st.markdown("## ğŸš€ ì˜¤ëŠ˜ì˜ AI ìœ ë§ ì¢…ëª© Top5")

def pick_promising_stocks(theme_rows, top_n=5):
    """
    í…Œë§ˆ ê°•ë„ + í‰ê·  ë“±ë½ë¥ ì„ ë°”íƒ•ìœ¼ë¡œ ìœ ë§ ì¢…ëª© ì„ ë³„
    1) í…Œë§ˆê°•ë„ ë†’ì€ ìˆœ
    2) ê·¸ í…Œë§ˆ ë‚´ ìƒìŠ¹ë¥  ìƒìœ„ ì¢…ëª©
    """
    candidates = []
    for tr in theme_rows[:8]:  # ìƒìœ„ í…Œë§ˆ ëª‡ ê°œë§Œ
        theme = tr["theme"]
        stocks = THEME_STOCKS.get(theme, [])
        for name, ticker in stocks:
            try:
                last, prev = fetch_quote(ticker)
                if not last or not prev:
                    continue
                delta = (last - prev) / prev * 100
                score = tr["count"] * 0.3 + delta * 0.7
                candidates.append({
                    "í…Œë§ˆ": theme,
                    "ì¢…ëª©ëª…": name,
                    "ë“±ë½ë¥ (%)": round(delta, 2),
                    "ë‰´ìŠ¤ë¹ˆë„": tr["count"],
                    "AIì ìˆ˜": round(score, 2),
                    "í‹°ì»¤": ticker
                })
            except Exception:
                continue

    df = pd.DataFrame(candidates)
    if df.empty:
        return pd.DataFrame()
    df = df.sort_values(by="AIì ìˆ˜", ascending=False).head(top_n)
    return df

recommend_df = pick_promising_stocks(theme_rows, top_n=5)

if recommend_df.empty:
    st.info("ì¶”ì²œí•  ì¢…ëª©ì´ ì—†ìŠµë‹ˆë‹¤. ë°ì´í„°ê°€ ë¶€ì¡±í•˜ê±°ë‚˜ ì‹œì¥ ë³€ë™ì„±ì´ ë‚®ìŠµë‹ˆë‹¤.")
else:
    st.dataframe(recommend_df, use_container_width=True, hide_index=True)
    st.markdown("### ğŸ§¾ AI ì¢…í•© íŒë‹¨")
    for _, row in recommend_df.iterrows():
        emoji = "ğŸ”º" if row["ë“±ë½ë¥ (%)"] > 0 else "ğŸ”»"
        st.markdown(
            f"**{emoji} {row['ì¢…ëª©ëª…']} ({row['í‹°ì»¤']})** â€” "
            f"í…Œë§ˆ: *{row['í…Œë§ˆ']}*, ìµœê·¼ ë“±ë½ë¥ : **{row['ë“±ë½ë¥ (%)']}%**, "
            f"ë‰´ìŠ¤ë¹ˆë„: {row['ë‰´ìŠ¤ë¹ˆë„']}ê±´, AIì ìˆ˜: {row['AIì ìˆ˜']}"
        )

st.caption("â€» AIì ìˆ˜ = ë‰´ìŠ¤í™œì„±ë„ + ì£¼ê°€ìƒìŠ¹ë¥  ê¸°ë°˜ ìœ ë§ë„ ì‚°ì¶œ")
# =====================================
# ğŸ”® 4ë‹¨ê³„: 'ë‚´ì¼ ì˜¤ë¥¼ í™•ë¥ ' 3ì¼ ì˜ˆì¸¡ ëª¨ë“ˆ
#  - ê° ì¢…ëª©ì˜ ê³¼ê±° ì¼ë´‰ìœ¼ë¡œ ê°„ë‹¨í•œ ë¡œì§€ìŠ¤í‹± íšŒê·€ë¥¼ í•™ìŠµ(ìŠ¬ë¼ì´ë”©, ëˆ„ìˆ˜ë°©ì§€)
#  - íŠ¹ì§•: ëª¨ë©˜í…€/ë³€ë™ì„±/RSI/ì´í‰ê´´ë¦¬/MACD
#  - ì¶œë ¥: ë‚´ì¼(+1) ìˆ˜ìµë¥ >0 í™•ë¥ , 3ì¼ í‰ê·  í™•ë¥ , ë§¤ìˆ˜/ê´€ë§ ì‹ í˜¸
# =====================================
st.divider()
st.markdown("## ğŸ”® AI 3ì¼ ì˜ˆì¸¡: ë‚´ì¼ ì˜¤ë¥¼ í™•ë¥ ")

import numpy as np
from sklearn.linear_model import LogisticRegression

if 'recommend_df' not in globals() or recommend_df.empty:
    st.info("ë¨¼ì € ìƒë‹¨ì˜ 'ìœ ë§ ì¢…ëª© Top5'ê°€ ìƒì„±ë˜ì–´ì•¼ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆì–´ìš”.")
else:
    # --------- ìœ í‹¸: ì§€í‘œ ----------
    def rsi(series: pd.Series, period: int = 14):
        delta = series.diff()
        up = np.where(delta > 0, delta, 0.0)
        down = np.where(delta < 0, -delta, 0.0)
        roll_up = pd.Series(up, index=series.index).rolling(period).mean()
        roll_down = pd.Series(down, index=series.index).rolling(period).mean()
        rs = roll_up / (roll_down.replace(0, np.nan))
        r = 100 - (100 / (1 + rs))
        return r.fillna(50)

    def macd(series: pd.Series, fast=12, slow=26, signal=9):
        ema_fast = series.ewm(span=fast, adjust=False).mean()
        ema_slow = series.ewm(span=slow, adjust=False).mean()
        macd_line = ema_fast - ema_slow
        signal_line = macd_line.ewm(span=signal, adjust=False).mean()
        hist = macd_line - signal_line
        return macd_line, signal_line, hist

    @st.cache_data(ttl=600)
    def load_hist(ticker: str, period="2y"):
        df = yf.download(ticker, period=period, interval="1d", auto_adjust=True, progress=False)
        # ì•¼í›„ ì¿¼í„°/íœ´ì¥ ì´ìŠˆ ë°©ì§€
        df = df[~df.index.duplicated(keep='last')].dropna()
        return df

    def build_features(df: pd.DataFrame):
        price = df["Close"]
        feat = pd.DataFrame(index=df.index)
        # ëª¨ë©˜í…€
        feat["ret_1d"] = price.pct_change(1)
        feat["ret_5d"] = price.pct_change(5)
        feat["ret_10d"] = price.pct_change(10)
        # ë³€ë™ì„±
        feat["vol_5d"] = df["Close"].pct_change().rolling(5).std()
        feat["vol_20d"] = df["Close"].pct_change().rolling(20).std()
        # RSI / MACD
        feat["rsi_14"] = rsi(price, 14)
        macd_line, signal_line, hist = macd(price)
        feat["macd"] = macd_line
        feat["macd_sig"] = signal_line
        feat["macd_hist"] = hist
        # ì´í‰ê´´ë¦¬
        ma5 = price.rolling(5).mean(); ma20 = price.rolling(20).mean()
        feat["ma5_gap"] = (price - ma5) / ma5
        feat["ma20_gap"] = (price - ma20) / ma20
        # íƒ€ê¹ƒ(ë‚´ì¼ ìƒìŠ¹?)
        tgt = (price.shift(-1) > price).astype(int)
        data = pd.concat([feat, tgt.rename("y")], axis=1).dropna()
        return data

    def fit_predict_prob(df_feat: pd.DataFrame):
        """
        ë‹¨ìˆœ ë¡œì§€ìŠ¤í‹± íšŒê·€. ìµœê·¼ 250ê±°ë˜ì¼ í•™ìŠµ, ë§ˆì§€ë§‰ 3ì¼ ì˜ˆì¸¡ í™•ë¥  ë°˜í™˜.
        ì‹œê³„ì—´ ëˆ„ìˆ˜ ë°©ì§€ë¥¼ ìœ„í•´ ê³¼ê±° êµ¬ê°„ë§Œìœ¼ë¡œ í•™ìŠµ.
        """
        if len(df_feat) < 120:
            return None, None  # ë°ì´í„° ë¶€ì¡±
        data = df_feat.copy().tail(300)  # ê³„ì‚° ê°€ë²¼ì›€ ìœ ì§€
        X = data.drop(columns=["y"]).values
        y = data["y"].values
        # í•™ìŠµ/ì˜ˆì¸¡ ë¶„ë¦¬: ë§ˆì§€ë§‰ 3ê°œë¥¼ 'ì˜ˆì¸¡ êµ¬ê°„'ìœ¼ë¡œ
        n = len(data)
        split = max(60, n - 3)  # ìµœì†Œ 60ì¼ì€ í•™ìŠµ í™•ë³´
        X_train, y_train = X[:split], y[:split]
        X_pred = X[split:]
        model = LogisticRegression(max_iter=200, n_jobs=None)
        model.fit(X_train, y_train)
        prob = model.predict_proba(X_pred)[:, 1]  # ìƒìŠ¹í™•ë¥ 
        # ë‚´ì¼(ê°€ì¥ ì²« ë²ˆì§¸ ì˜ˆì¸¡)ê³¼ 3ì¼ í‰ê· 
        p_tomorrow = float(prob[0]) if len(prob) > 0 else None
        p_3avg = float(prob.mean()) if len(prob) > 0 else None
        return p_tomorrow, p_3avg

    rows = []
    with st.spinner("ì˜ˆì¸¡ ê³„ì‚° ì¤‘..."):
        for _, r in recommend_df.iterrows():
            name, ticker = r["ì¢…ëª©ëª…"], r["í‹°ì»¤"]
            try:
                hist = load_hist(ticker)
                feats = build_features(hist)
                p1, p3 = fit_predict_prob(feats)
                if p1 is None:
                    rows.append({"ì¢…ëª©ëª…": name, "í‹°ì»¤": ticker, "ë‚´ì¼ìƒìŠ¹í™•ë¥ ": "-", "3ì¼í‰ê· í™•ë¥ ": "-", "ì‹ í˜¸": "ë°ì´í„°ë¶€ì¡±"})
                    continue
                signal = "ë§¤ìˆ˜ê´€ì‹¬" if p1 >= 0.55 else ("ê´€ë§" if p1 >= 0.45 else "ì£¼ì˜")
                rows.append({
                    "ì¢…ëª©ëª…": name,
                    "í‹°ì»¤": ticker,
                    "ë‚´ì¼ìƒìŠ¹í™•ë¥ ": round(p1 * 100, 1),
                    "3ì¼í‰ê· í™•ë¥ ": round(p3 * 100, 1),
                    "ì‹ í˜¸": signal
                })
            except Exception:
                rows.append({"ì¢…ëª©ëª…": name, "í‹°ì»¤": ticker, "ë‚´ì¼ìƒìŠ¹í™•ë¥ ": "-", "3ì¼í‰ê· í™•ë¥ ": "-", "ì‹ í˜¸": "ì˜¤ë¥˜"})

    pred_df = pd.DataFrame(rows)

    if pred_df.empty:
        st.info("ì˜ˆì¸¡ì„ í‘œì‹œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        # ìƒ‰ìƒ í•˜ì´ë¼ì´íŠ¸: í™•ë¥ /ì‹ í˜¸
        def _prob_color(v):
            try:
                v = float(v)
            except:
                return ""
            if v >= 60:  # ë†’ìŒ
                return "background-color: rgba(217,48,37,0.2); color:#ffd2cf; font-weight:700;"
            if v >= 50:  # ë³´í†µ
                return "background-color: rgba(255,193,7,0.15);"
            return "background-color: rgba(26,115,232,0.18); color:#d7e6ff;"

        st.dataframe(
            pred_df.style.map(_prob_color, subset=["ë‚´ì¼ìƒìŠ¹í™•ë¥ ", "3ì¼í‰ê· í™•ë¥ "]),
            use_container_width=True, hide_index=True
        )

        # ìš”ì•½ ë¬¸ì¥
        st.markdown("### ğŸ§  AI ì¸ì‚¬ì´íŠ¸")
        for _, row in pred_df.iterrows():
            if row["ë‚´ì¼ìƒìŠ¹í™•ë¥ "] == "-":
                st.markdown(f"- **{row['ì¢…ëª©ëª…']} ({row['í‹°ì»¤']})** â€” ë°ì´í„° ë¶€ì¡±/ì˜¤ë¥˜ë¡œ ì˜ˆì¸¡ ìƒëµ")
            else:
                arrow = "ğŸ”º" if row["ë‚´ì¼ìƒìŠ¹í™•ë¥ "] >= 50 else "ğŸ”»"
                st.markdown(
                    f"- **{row['ì¢…ëª©ëª…']} ({row['í‹°ì»¤']})** â€” ë‚´ì¼ ìƒìŠ¹ í™•ë¥  **{row['ë‚´ì¼ìƒìŠ¹í™•ë¥ ']}%** "
                    f"(3ì¼ í‰ê·  {row['3ì¼í‰ê· í™•ë¥ ']}%), ì‹ í˜¸: **{row['ì‹ í˜¸']}** {arrow}"
                )

st.caption("â€» ê°„ë‹¨í•œ ë¡œì§€ìŠ¤í‹± íšŒê·€ ê¸°ë°˜ ì°¸ê³ ì§€í‘œì…ë‹ˆë‹¤. íˆ¬ì íŒë‹¨ì˜ ì±…ì„ì€ ë³¸ì¸ì—ê²Œ ìˆìŠµë‹ˆë‹¤.")
