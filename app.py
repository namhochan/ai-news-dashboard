# app.py â€” ì•ˆì •íŒ (ìž…ë ¥ ì •ê·œí™” ì¶”ê°€)
import re, json
from datetime import datetime, timezone, timedelta
from typing import Any, Dict, List, Tuple

import streamlit as st
import pandas as pd
import yfinance as yf
import feedparser

# ---------- ê³µí†µ ----------
KST = timezone(timedelta(hours=9))
st.set_page_config(page_title="AI ë‰´ìŠ¤ë¦¬í¬íŠ¸ ì¢…í•© ëŒ€ì‹œë³´ë“œ", layout="wide")
st.markdown("# ðŸ§  AI ë‰´ìŠ¤ë¦¬í¬íŠ¸ ì¢…í•© ëŒ€ì‹œë³´ë“œ (ìžë™ ì—…ë°ì´íŠ¸)")
st.caption("ì—…ë°ì´íŠ¸ ì‹œê°„: " + datetime.now(KST).strftime("%Y-%m-%d %H:%M:%S (KST)"))

def to_float(x):
    try:
        return float(x) if x is not None else None
    except:
        return None

# ---------- ì§€ìˆ˜/í™˜ìœ¨/ì›ìžìž¬ ----------
SYMS = {
    "KOSPI":  ["^KS11"],
    "KOSDAQ": ["^KQ11", "^KOSDAQ"],
    "USDKRW": ["KRW=X"],
    "WTI":    ["CL=F"],
    "Gold":   ["GC=F"],
    "Copper": ["HG=F"],
}

def _last_two_close(ticker: str):
    try:
        df = yf.download(ticker, period="10d", interval="1d", progress=False)
        closes = df["Close"].dropna().tail(2).tolist()
        if len(closes) == 2:
            return closes[-1], closes[-2]
        elif len(closes) == 1:
            return closes[0], None
    except:
        pass
    return None, None

def get_market_block():
    out = {}
    for name, cands in SYMS.items():
        cur = prev = None
        for t in cands:
            cur, prev = _last_two_close(t)
            if cur is not None:
                break
        if cur is None:
            out[name] = {"value": "-", "change": None}
        else:
            chg = None if prev is None else round((cur - prev) / prev * 100, 2)
            out[name] = {"value": round(cur, 2), "change": chg}
    return out

# ---------- ë‰´ìŠ¤ ìˆ˜ì§‘ (Google News RSS) ----------
def google_rss(query: str) -> str:
    from urllib.parse import quote
    return f"https://news.google.com/rss/search?q={quote(query)}&hl=ko&gl=KR&ceid=KR:ko"

NEWS_QUERIES = [
    "site:mk.co.kr ê²½ì œ",
    "site:hankyung.com ê²½ì œ",
    "site:biz.chosun.com ì‚°ì—…",
    "site:yna.co.kr ì •ì±…",
    "site:policy.go.kr ì •ì±…ë¸Œë¦¬í•‘",
]

def normalize_item(x) -> Dict[str, str]:
    """ë‰´ìŠ¤ í•­ëª©ì„ ë¬´ì¡°ê±´ {'title': str, 'link': str} í˜•íƒœë¡œ ë§žì¶¤"""
    if isinstance(x, dict) or "FeedParserDict" in x.__class__.__name__:
        t = str(x.get("title", "")).strip()
        l = str(x.get("link", "")).strip()
        return {"title": t, "link": l}
    # ë¬¸ìžì—´ ë“± ê¸°íƒ€ íƒ€ìž…
    s = str(x).strip()
    return {"title": s, "link": ""}

def fetch_headlines_top10() -> List[Dict[str, str]]:
    items: List[Dict[str, str]] = []
    for q in NEWS_QUERIES:
        url = google_rss(q)
        try:
            feed = feedparser.parse(url)
            for e in feed.entries[:6]:  # ê° ì†ŒìŠ¤ ìµœëŒ€ 6ê±´
                items.append(normalize_item(e))
        except Exception:
            continue
    # í´ë¦°ì—…
    clean = []
    seen = set()
    for n in items:
        t, l = n.get("title", ""), n.get("link", "")
        if not t:
            continue
        if t in seen:
            continue
        seen.add(t)
        clean.append({"title": t, "link": l})
    return clean[:10]

# ---------- í…Œë§ˆ ìŠ¤ì½”ì–´ë§ ----------
THEMES = {
    "AI": ["AI", "ì¸ê³µì§€ëŠ¥", "ìƒì„±í˜•", "ì±—GPT", "LLM"],
    "ë°˜ë„ì²´": ["ë°˜ë„ì²´", "HBM", "GPU", "íŒŒìš´ë“œë¦¬", "ë©”ëª¨ë¦¬"],
    "ì´ì°¨ì „ì§€": ["ì´ì°¨ì „ì§€", "ë°°í„°ë¦¬", "ì–‘ê·¹ìž¬", "ìŒê·¹ìž¬", "ì „ê³ ì²´"],
    "ë¡œë´‡": ["ë¡œë´‡", "ìžìœ¨ì£¼í–‰", "íœ´ë¨¸ë…¸ì´ë“œ", "í˜‘ë™ë¡œë´‡"],
    "ë°”ì´ì˜¤": ["ë°”ì´ì˜¤", "ì œì•½", "ì˜ì•½í’ˆ", "ìž„ìƒ"],
    "ì¡°ì„ ": ["ì¡°ì„ ", "ì„ ë°•", "í•´ìš´", "LNGì„ "],
    "ì›ì „": ["ì›ì „", "SMR", "ì›ìžë ¥"],
}

REP_STOCKS = {
    "AI": ["ì‚¼ì„±ì „ìž", "ë„¤ì´ë²„", "ì¹´ì¹´ì˜¤", "ë”ì¡´ë¹„ì¦ˆì˜¨"],
    "ë°˜ë„ì²´": ["ì‚¼ì„±ì „ìž", "SKí•˜ì´ë‹‰ìŠ¤", "DBí•˜ì´í…"],
    "ì´ì°¨ì „ì§€": ["LGì—ë„ˆì§€ì†”ë£¨ì…˜", "í¬ìŠ¤ì½”í“¨ì²˜ì— ", "ì—ì½”í”„ë¡œ"],
    "ë¡œë´‡": ["ë ˆì¸ë³´ìš°ë¡œë³´í‹±ìŠ¤", "ìœ ì§„ë¡œë´‡"],
    "ë°”ì´ì˜¤": ["ì‚¼ì„±ë°”ì´ì˜¤ë¡œì§ìŠ¤", "ì…€íŠ¸ë¦¬ì˜¨"],
    "ì¡°ì„ ": ["HDí•œêµ­ì¡°ì„ í•´ì–‘", "ì‚¼ì„±ì¤‘ê³µì—…"],
    "ì›ì „": ["ë‘ì‚°ì—ë„ˆë¹Œë¦¬í‹°", "í•œì „KPS"],
}

def score_themes(news: List[Dict[str, str]]) -> pd.DataFrame:
    counts = {k: 0 for k in THEMES}
    sample = {k: "" for k in THEMES}
    for raw in news:
        n = normalize_item(raw)        # ðŸ’¡ ì—¬ê¸°ì„œ í˜•íƒœ ê°•ì œ
        title = n.get("title", "")
        link = n.get("link", "")
        for th, keys in THEMES.items():
            if any(k in title for k in keys):
                counts[th] += 1
                if not sample[th]:
                    sample[th] = link
    rows = []
    for th, c in counts.items():
        if c > 0:
            rows.append({
                "theme": th,
                "count": c,
                "rep_stocks": " Â· ".join(REP_STOCKS.get(th, [])),
                "sample_link": sample[th]
            })
    return pd.DataFrame(rows).sort_values("count", ascending=False)

def extract_keywords(news: List[Dict[str, str]]) -> pd.DataFrame:
    bag: Dict[str, int] = {}
    for raw in news:
        n = normalize_item(raw)
        for w in re.findall(r"[ê°€-íž£A-Za-z0-9]+", n.get("title", "")):
            if len(w) < 2:
                continue
            bag[w] = bag.get(w, 0) + 1
    top = sorted(bag.items(), key=lambda x: x[1], reverse=True)[:30]
    return pd.DataFrame(top, columns=["keyword", "count"])

# ---------- ë°ì´í„° ìƒì„± ----------
market = get_market_block()
headlines = fetch_headlines_top10()
themes_df = score_themes(headlines) if headlines else pd.DataFrame(columns=["theme", "count", "rep_stocks", "sample_link"])
keywords_df = extract_keywords(headlines) if headlines else pd.DataFrame(columns=["keyword", "count"])

# ---------- UI ----------
def metric(col, title, obj):
    val, chg = obj["value"], obj["change"]
    if val == "-":
        col.metric(title, value="-", delta="None")
    else:
        col.metric(title, value=f"{val:,.2f}", delta=("None" if chg is None else f"{chg:+.2f}%"))

st.subheader("ðŸ“Š ì˜¤ëŠ˜ì˜ ì‹œìž¥ ìš”ì•½")
c1, c2, c3 = st.columns(3)
c4, c5, c6 = st.columns(3)
metric(c1, "KOSPI", market["KOSPI"])
metric(c2, "KOSDAQ", market["KOSDAQ"])
metric(c3, "í™˜ìœ¨(USD/KRW)", market["USDKRW"])
metric(c4, "WTI", market["WTI"])
metric(c5, "Gold", market["Gold"])
metric(c6, "Copper", market["Copper"])

st.divider()
st.subheader("ðŸ“° ìµœì‹  ê²½ì œÂ·ì •ì±…Â·ì‚°ì—…Â·ë¦¬í¬íŠ¸ ë‰´ìŠ¤ TOP 10")
if not headlines:
    st.info("í—¤ë“œë¼ì¸ ì—†ìŒ")
else:
    for i, n in enumerate(headlines, start=1):
        n = normalize_item(n)
        t = n.get("title", "")
        l = n.get("link", "")
        if l:
            st.markdown(f"{i}. [{t}]({l})")
        else:
            st.markdown(f"{i}. {t}")

st.divider()
st.subheader("ðŸ”¥ ë‰´ìŠ¤ ê¸°ë°˜ TOP í…Œë§ˆ")
if themes_df.empty:
    st.info("í…Œë§ˆ ë°ì´í„° ì—†ìŒ")
else:
    st.bar_chart(themes_df.set_index("theme")["count"])
    st.dataframe(themes_df, use_container_width=True)

st.divider()
st.subheader("ðŸŒ ì›”ê°„ í‚¤ì›Œë“œë§µ (ìµœê·¼ 30ì¼)")
if keywords_df.empty:
    st.info("í‚¤ì›Œë“œ ì—†ìŒ")
else:
    st.bar_chart(keywords_df.set_index("keyword")["count"])

st.success("âœ… ëŒ€ì‹œë³´ë“œ ë¡œë”© ì™„ë£Œ (ê°•í™”ëœ ìž…ë ¥ ì •ê·œí™” ì ìš©)")
